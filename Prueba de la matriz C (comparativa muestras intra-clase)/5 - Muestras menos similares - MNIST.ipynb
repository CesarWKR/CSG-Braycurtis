{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añadir el directorio raíz del proyecto a sys.path\n",
    "module_path = Path('/Users/Cesar/Desktop/Proyecto-CSG/').resolve()\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(str(module_path))\n",
    "\n",
    "# Añadir el directorio que contiene 'new_spectral_metric' a sys.path\n",
    "new_spectral_metric_path = module_path / '/Users/Cesar/Desktop/Proyecto-CSG/new_spectral_metric/'\n",
    "if new_spectral_metric_path not in sys.path:\n",
    "    sys.path.append(str(new_spectral_metric_path))\n",
    "\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "# from spectral_metric.lib import find_samples, compute_expectation_with_monter_carlo \n",
    "from new_spectral_metric.new_estimator_intra_class import CumulativeGradientEstimator\n",
    "from new_spectral_metric.new_visualize import make_graph\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, Dense, MaxPooling2D, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET DESDE DIRECTORIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de dataset\n",
    "\n",
    "directorio_dataset = ('../Datasets/MNIST')\n",
    "directorio_dataset = pathlib.Path(directorio_dataset)\n",
    "\n",
    "# Lectura de la carpeta train\n",
    "directorio_train = ('../Datasets/MNIST/train')\n",
    "directorio_train = pathlib.Path(directorio_train)\n",
    "\n",
    "# Lectura de la carpeta test\n",
    "directorio_test = ('../Datasets/MNIST/test')\n",
    "directorio_test = pathlib.Path(directorio_test)\n",
    "\n",
    "total_dataset = len(list(directorio_dataset.glob('*/*/*.png')))  # Cuenta la cantidad de imagenes del dataset (Aqui busca en las subcarpetas del directorio del dataset)\n",
    "total_train = len(list(directorio_train.glob('*/*.png')))  # Cuenta la cantidad de imagenes de train\n",
    "total_test = len(list(directorio_test.glob('*/*.png')))  # Cuenta la cantidad de imagenes de test\n",
    "\n",
    "print(f\"Total imagenes dataset: {total_dataset}\")\n",
    "print(f\"Total imagenes train: {total_train}\")\n",
    "print(f\"Total imagenes test: {total_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el batchsize del dataset completo\n",
    "batch_size_total = total_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de imagen y tamaño de batch en train\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "#batch_size = 32\n",
    "batch_size_train = total_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "# Data splitting (entrenamiento y validación)\n",
    "train_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  directorio_train,\n",
    "  #validation_split=0.2,\n",
    "  color_mode='rgb',\n",
    "  label_mode='int',\n",
    "  #subset=\"training\",\n",
    "  #seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de imagen y tamaño de batch en test\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "#batch_size = 32\n",
    "batch_size_test = total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (entrenamiento y validación)\n",
    "test_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  directorio_test,\n",
    "  #validation_split=0.2,\n",
    "  color_mode='rgb',\n",
    "  label_mode='int',\n",
    "  #subset=\"training\",\n",
    "  #seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el total de imágenes por clase en train y test  \n",
    "class_counts_total = {p.name: len(list(p.glob('*.png'))) for p in directorio_dataset.glob('*/*')}  \n",
    "class_counts_train = {p.name: len(list(p.glob('*.png'))) for p in directorio_train.glob('*')}  \n",
    "class_counts_test = {p.name: len(list(p.glob('*.png'))) for p in directorio_test.glob('*')}  \n",
    "\n",
    "# Encontrar el valor más bajo de imágenes por clase en train  \n",
    "menor_train = min(class_counts_train.values()) if class_counts_train else None  # Se almacena el valor de la clase que menos muestras tiene\n",
    "\n",
    "# Encontrar el valor más alto de imágenes por clase en train  \n",
    "mayor_train = max(class_counts_train.values()) if class_counts_train else None  # Se almacena el valor de la clase que mas muestras tiene\n",
    "\n",
    "\n",
    "# Encontrar el valor más bajo de imágenes por clase en test  \n",
    "menor_test = min(class_counts_test.values()) if class_counts_test else None  # Se almacena el valor de la clase que menos muestras tiene\n",
    "\n",
    "# Encontrar el valor más alto de imágenes por clase en test  \n",
    "mayor_test = max(class_counts_test.values()) if class_counts_test else None  # Se almacena el valor de la clase que mas muestras tiene\n",
    "\n",
    "\n",
    "# Mostrar el total de imágenes por clase en train  \n",
    "print(\"\\nTotal de imágenes por clase en train:\")  \n",
    "for class_name, count in class_counts_train.items():  \n",
    "    print(f\"Clase: {class_name}, Número de imágenes: {count}\")  \n",
    "print(f\"Total imágenes train: {sum(class_counts_train.values())}\")  \n",
    "\n",
    "# Mostrar el valor más bajo en train  \n",
    "print(f\"Menor número de imágenes en train: {menor_train}\")  \n",
    "\n",
    "# Mostrar el valor más alto en train  \n",
    "print(f\"Mayor número de imágenes en train: {mayor_train}\")  \n",
    "\n",
    "# Mostrar el total de imágenes por clase en test  \n",
    "print(\"\\nTotal de imágenes por clase en test:\")  \n",
    "for class_name, count in class_counts_test.items():  \n",
    "    print(f\"Clase: {class_name}, Número de imágenes: {count}\")  \n",
    "print(f\"Total imágenes test: {sum(class_counts_test.values())}\")  \n",
    "\n",
    "# Mostrar el valor más bajo en test  \n",
    "print(f\"Menor número de imágenes en test: {menor_test}\")\n",
    "\n",
    "# Mostrar el valor más alto en test  \n",
    "print(f\"Mayor número de imágenes en test: {mayor_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las clases\n",
    "class_names_train = list(class_counts_train.keys())\n",
    "class_names_test = list(class_counts_test.keys())\n",
    "#class_names_total = sorted(list(set(class_names_train + class_names_test)))\n",
    "class_names_total = list(class_counts_total.keys())\n",
    "\n",
    "# Mostrar el número de clases y los nombres\n",
    "print(f\"\\nNúmero de clases en train: {len(class_names_train)}\")\n",
    "print(f\"Nombres de las clases en train: {class_names_train}\")\n",
    "\n",
    "print(f\"\\nNúmero de clases en test: {len(class_names_test)}\")\n",
    "print(f\"Nombres de las clases en test: {class_names_test}\")\n",
    "\n",
    "print(f\"\\nNúmero total de clases en el dataset: {len(class_names_total)}\")   # Este valor cambia si el nombre de las clases es diferente\n",
    "print(f\"Nombres de todas las clases en el dataset: {class_names_total}\")     # Este valor tambien cambia si el nombre de las clases es diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels0 in train_images.take(1):  # only take first element of dataset\n",
    "    numpy_all_images = images.numpy()  # convertir el tensor de imágenes en un arreglo de numpy y ahora contiene las imágenes del conjunto de datos en formato de numpy.\n",
    "    numpy_all_labels = labels0.numpy()  # convierte el tensor de etiquetas en un arreglo de numpy y ahora contiene las etiquetas del conjunto de datos en formato de numpy\n",
    "\n",
    "numpy_all_images /= 255.0  # Scale the features to the [0, 1] range\n",
    "print(numpy_all_images.shape)\n",
    "\n",
    "# CIFAR-10 \n",
    "fully_dataset_train = numpy_all_images.reshape((numpy_all_images.shape[0], numpy_all_images.shape[1]*numpy_all_images.shape[2]*numpy_all_images.shape[3])) # es un arreglo bidimensional donde cada fila representa una imagen y cada columna representa un píxel de la imagen\n",
    "fully_labels_train = numpy_all_labels.reshape(numpy_all_labels.shape[0],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset complexity using CSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = CumulativeGradientEstimator(M_sample=mayor_train, k_nearest=10)  # Utiliza el numero menor de muestras encontrado en cada clase dependiendo si es train o test\n",
    "estimator.fit(data=fully_dataset_train, target=fully_labels_train)\n",
    "csg = estimator.csg  # The actual complexity values.\n",
    "estimator.evals, estimator.evecs  # The eigenvalues and vectors.\n",
    "\n",
    "make_graph(estimator.difference, title=\"Dataset Complexity - MNIST: \"+str(csg), classes=class_names_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular la similitud entre clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "\n",
    "# Calcular la entropía por clase  \n",
    "entropy_per_class = entropy(estimator.W / estimator.W.sum(-1)[:, None], axis=-1)  \n",
    "\n",
    "# Encontrar la clase menos confusa (menor entropía)  \n",
    "least_confused_class_index = np.argmin(entropy_per_class)  \n",
    "least_confused_class_name = class_names_train[least_confused_class_index]  \n",
    "\n",
    "print(\"Class that is the least confused (lowest entropy):\", least_confused_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener los índices de los pares menos similares  \n",
    "pairs = list(zip(*np.unravel_index(np.argsort(estimator.W, axis=None), estimator.W.shape)))  \n",
    "\n",
    "# Filtrar pares donde i != j para evitar pares de la misma clase  \n",
    "pairs = [(i, j) for i, j in pairs if i != j]  \n",
    "\n",
    "print(\"Least similar pairs\")  \n",
    "lst = []  \n",
    "seen_pairs = set()  \n",
    "\n",
    "# Iterar sobre los primeros 10 pares menos similares  \n",
    "for i, j in pairs:  \n",
    "    # Verificar si el par o su inverso ya ha sido visto  \n",
    "    if (i, j) not in seen_pairs and (j, i) not in seen_pairs:  \n",
    "        lst.append({\"Intent pair\": f\"{class_names_train[i]} <> {class_names_train[j]}\", \"Similarity\": estimator.W[i, j]})  \n",
    "        seen_pairs.add((i, j))  \n",
    "        seen_pairs.add((j, i))  \n",
    "    \n",
    "    # Detenerse después de encontrar 10 pares únicos  \n",
    "    if len(lst) == 10:  \n",
    "        break  \n",
    "\n",
    "# Mostrar los resultados en un DataFrame  \n",
    "print(pd.DataFrame(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener los nombres de las imagenes en train o test (dependiendo de lo que se quiera probar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los nombres de archivo en el dataset\n",
    "filenames = [str(f) for f in directorio_train.glob('*/*.png')]\n",
    "\n",
    "# Crear un mapeo de índices a rutas completas de archivo  \n",
    "filenames_dict = {i: str(f) for i, f in enumerate(directorio_train.glob('*/*.png'))} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular la similitud entre muestras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Visualizar las muestras (par de imagenes) menos similares entre la misma clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportar la matriz en un txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Función para encontrar y mostrar las imágenes menos similares dentro de cada clase usando la matriz C  \n",
    "# def show_least_similar_using_C_all_classes(estimator, class_names, filenames_dict):  \n",
    "#     images_to_show = []  # Lista para almacenar las imágenes y sus detalles  \n",
    "\n",
    "#     # Recorre las clases y genera la lista de descripciones  \n",
    "#     for class_intent in range(len(class_names)):  \n",
    "#         class_name = class_names[class_intent]  \n",
    "#         print(f\"Clase: {class_name}\")  \n",
    "        \n",
    "#         # Obtener la matriz de similitud de las muestras dentro de la clase  \n",
    "#         C = estimator.C[class_intent]  \n",
    "\n",
    "#         # Imprimir la forma de la matriz de similitud de la clase  \n",
    "#         print(f\"Forma de la matriz de similitud de la clase {class_name}: {C.shape}\")  \n",
    "\n",
    "#         # Exportar la matriz de similitud a un archivo de texto  \n",
    "#         with open(f\"similarity_matrix_{class_name}.txt\", \"w\") as file:  \n",
    "#             file.write(f\"Matriz de Similitud para la Clase: {class_name}\\n\")  \n",
    "#             file.write(\"\\t\" + \"\\t\".join([Path(filenames_dict[i]).name for i in estimator.class_indices[class_intent]]) + \"\\n\")  \n",
    "#             for i, row in enumerate(C):  \n",
    "#                 row_name = Path(filenames_dict[estimator.class_indices[class_intent][i]]).name  \n",
    "#                 row_values = \"\\t\".join([f\"{value:.4f}\" for value in row])  \n",
    "#                 file.write(f\"{row_name}\\t{row_values}\\n\")  \n",
    "        \n",
    "#         # Ordenar los índices según las similitudes (de menor a mayor)  \n",
    "#         least_similar_indices = np.argsort(C, axis=None)  \n",
    "\n",
    "#         shown_pairs = set()  # Para rastrear los pares de índices ya mostrados  \n",
    "#         count = 0  \n",
    "#         show_samples = 20  # Número de muestras para visualizar la similitud  \n",
    "\n",
    "#         # Diccionario para contar la participación de cada imagen  \n",
    "#         participation_count = {}  \n",
    "\n",
    "#         for idx in least_similar_indices:  \n",
    "#             if count >= show_samples:  \n",
    "#                 break  \n",
    "            \n",
    "#             # Convertir el índice plano a índice 2D  \n",
    "#             idx_2d = np.unravel_index(idx, C.shape)  \n",
    "            \n",
    "#             # Saltar las comparaciones de una muestra consigo misma  \n",
    "#             if idx_2d[0] == idx_2d[1]:  \n",
    "#                 continue  \n",
    "            \n",
    "#             # Crear un par ordenado de índices para prevenir duplicados  \n",
    "#             index_pair = tuple(sorted((idx_2d[0], idx_2d[1])))  \n",
    "            \n",
    "#             # Verificamos si el par ya fue mostrado  \n",
    "#             if index_pair in shown_pairs:  \n",
    "#                 continue  \n",
    "            \n",
    "#             shown_pairs.add(index_pair)  \n",
    "            \n",
    "#             # Actualizar el conteo de participación  \n",
    "#             participation_count[idx_2d[0]] = participation_count.get(idx_2d[0], 0) + 1  \n",
    "#             participation_count[idx_2d[1]] = participation_count.get(idx_2d[1], 0) + 1  \n",
    "\n",
    "#             # Obtener los índices de las muestras en el dataset  \n",
    "#             source_idx = estimator.class_indices[class_intent][idx_2d[0]]  \n",
    "#             target_idx = estimator.class_indices[class_intent][idx_2d[1]]  \n",
    "            \n",
    "#             # Verificar que los índices estén dentro de los límites del dataset  \n",
    "#             if source_idx < len(filenames_dict) and target_idx < len(filenames_dict):  \n",
    "#                 source_filename = Path(filenames_dict[int(source_idx)])  \n",
    "#                 target_filename = Path(filenames_dict[int(target_idx)])  \n",
    "                \n",
    "#                 value = C[idx_2d]  \n",
    "                \n",
    "#                 # Formatear y mostrar la salida  \n",
    "#                 print(f\"\\t{source_filename.name} ({class_name}) vs {target_filename.name} ({class_name}), Similitud: {value:.4f}\")  \n",
    "                \n",
    "#                 # Agrega los detalles a la lista para visualización  \n",
    "#                 images_to_show.append((source_filename, target_filename, class_name, value))  \n",
    "                \n",
    "#                 count += 1  \n",
    "\n",
    "#         # Encontrar las muestras más atípicas      \n",
    "#         most_atypical = sorted(participation_count.items(), key=lambda x: -x[1])  \n",
    "        \n",
    "#         # Mostrar las 10 más atípicas  \n",
    "#         print(\"\\nMuestras más atípicas de esta clase:\")  \n",
    "#         for rank, (img_idx, freq) in enumerate(most_atypical[:10], 1):  \n",
    "#             img_name = Path(filenames_dict[int(estimator.class_indices[class_intent][img_idx])]).name  \n",
    "#             print(f\"\\t#{rank}: {img_name} con {freq} apariciones\")  \n",
    "#         print(\"\\n\")  \n",
    "\n",
    "#     # Luego, realiza la visualización de las imágenes  \n",
    "#     for source_filename, target_filename, class_name, value in images_to_show:  \n",
    "#         img_source = plt.imread(source_filename)  \n",
    "#         img_target = plt.imread(target_filename)  \n",
    "        \n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(5, 3))  \n",
    "#         axs[0].imshow(img_source)  \n",
    "#         axs[0].set_title(f\"{class_name}: \\n{source_filename.name}\", fontsize=8)  \n",
    "#         axs[0].axis('off')  # Elimina los ejes para centrar la atención en la imagen  \n",
    "        \n",
    "#         axs[1].imshow(img_target)  \n",
    "#         axs[1].set_title(f\"{class_name}: \\n{target_filename.name}\", fontsize=8)  \n",
    "#         axs[1].axis('off')  \n",
    "#         plt.suptitle(f\"Similitud: {value:.4f}\")  \n",
    "#         plt.subplots_adjust(wspace=0.3, hspace=0.3)  # Ajusta el espacio entre subtramas  \n",
    "#         plt.show()  \n",
    "\n",
    "# print(\"Muestras menos similares entre las imágenes de la misma clase \\n\")  \n",
    "# show_least_similar_using_C_all_classes(estimator, class_names_train, filenames_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizacion de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para encontrar y mostrar las imágenes menos similares dentro de cada clase usando la matriz C  \n",
    "def show_least_similar_using_C_all_classes(estimator, class_names, filenames_dict):  \n",
    "    images_to_show = []  # Lista para almacenar las imágenes y sus detalles  \n",
    "\n",
    "    # Primero, recorre las clases y genera la lista de descripciones  \n",
    "    for class_intent in range(len(class_names)):  \n",
    "        class_name = class_names[class_intent]  \n",
    "        print(f\"Clase: {class_name}\")  \n",
    "        \n",
    "        # Obtener la matriz de similitud de las muestras dentro de la clase  \n",
    "        C = estimator.C[class_intent]  \n",
    "\n",
    "        # Imprimir la forma de la matriz de similitud de la clase  \n",
    "        print(f\"Forma de la matriz de la clase {class_name}: {C.shape}\")\n",
    "        \n",
    "        # Ordenar los índices según las similitudes (de menor a mayor)  \n",
    "        least_similar_indices = np.argsort(C, axis=None)  \n",
    "        \n",
    "        shown_pairs = set()  # Para rastrear los pares de índices ya mostrados  \n",
    "        count = 0  \n",
    "        show_samples = 20  # Número de muestras para visualizar la similitud  \n",
    "        \n",
    "        # Diccionario para contar la participación de cada imagen  \n",
    "        participation_count = {}\n",
    "\n",
    "        for idx in least_similar_indices:  \n",
    "            if count >= show_samples:  \n",
    "                break  \n",
    "            \n",
    "            # Convertir el índice plano a índice 2D  \n",
    "            idx_2d = np.unravel_index(idx, C.shape)  \n",
    "            \n",
    "            # Saltar las comparaciones de una muestra consigo misma  \n",
    "            if idx_2d[0] == idx_2d[1]:  \n",
    "                continue  \n",
    "            \n",
    "            # Crear un par ordenado de índices para prevenir duplicados  \n",
    "            index_pair = tuple(sorted((idx_2d[0], idx_2d[1])))  \n",
    "            \n",
    "            # Verificamos si el par ya fue mostrado  \n",
    "            if index_pair in shown_pairs:  \n",
    "                continue  \n",
    "            \n",
    "            shown_pairs.add(index_pair)  \n",
    "            \n",
    "            # Actualizar el conteo de participación  \n",
    "            participation_count[idx_2d[0]] = participation_count.get(idx_2d[0], 0) + 1  \n",
    "            participation_count[idx_2d[1]] = participation_count.get(idx_2d[1], 0) + 1\n",
    "\n",
    "            # Obtener los índices de las muestras en el dataset  \n",
    "            source_idx = estimator.class_indices[class_intent][idx_2d[0]]  \n",
    "            target_idx = estimator.class_indices[class_intent][idx_2d[1]]  \n",
    "            \n",
    "            # Verificar que los índices estén dentro de los límites del dataset  \n",
    "            if source_idx < len(filenames_dict) and target_idx < len(filenames_dict):  \n",
    "                source_filename = Path(filenames_dict[int(source_idx)])  \n",
    "                target_filename = Path(filenames_dict[int(target_idx)])  \n",
    "                \n",
    "                value = C[idx_2d]  \n",
    "                \n",
    "                # Formatear y mostrar la salida  \n",
    "                print(f\"\\t{source_filename.name} ({class_name}) vs {target_filename.name} ({class_name}), Similitud: {value:.4f}\")  \n",
    "                \n",
    "                # Agrega los detalles a la lista para visualización  \n",
    "                images_to_show.append((source_filename, target_filename, class_name, value))  \n",
    "                \n",
    "                count += 1  \n",
    "    \n",
    "\n",
    "        # Encontrar las muestras más atípicas  \n",
    "        most_atypical = sorted(participation_count.items(), key=lambda x: -x[1])  \n",
    "        \n",
    "        # Mostrar las 10 más atípicas  \n",
    "        print(\"\\nMuestras más atípicas de esta clase:\")  \n",
    "        for rank, (img_idx, freq) in enumerate(most_atypical[:10], 1):  \n",
    "            img_name = Path(filenames_dict[int(estimator.class_indices[class_intent][img_idx])]).name  \n",
    "            print(f\"\\t#{rank}: {img_name} con {freq} apariciones\")  \n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "    # Luego, realiza la visualización de las imágenes  \n",
    "    for source_filename, target_filename, class_name, value in images_to_show:  \n",
    "        img_source = plt.imread(source_filename)  \n",
    "        img_target = plt.imread(target_filename)  \n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(5, 3))  \n",
    "        axs[0].imshow(img_source)  \n",
    "        axs[0].set_title(f\"{class_name}: \\n{source_filename.name}\", fontsize=8) \n",
    "        axs[0].axis('off')  # Elimina los ejes para centrar la atención en la imagen  \n",
    "        \n",
    "        axs[1].imshow(img_target)  \n",
    "        axs[1].set_title(f\"{class_name}: \\n{target_filename.name}\", fontsize=8)  \n",
    "        axs[1].axis('off') \n",
    "        plt.suptitle(f\"Similitud: {value:.4f}\")  \n",
    "        plt.subplots_adjust(wspace=0.3, hspace=0.3)  # Ajusta el espacio entre subtramas  \n",
    "        plt.show()  \n",
    "\n",
    "\n",
    "print(\"Muestras menos similares entre las imágenes de la misma clase \\n\")  \n",
    "show_least_similar_using_C_all_classes(estimator, class_names_train, filenames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv  \n",
    "# from pathlib import Path  \n",
    "\n",
    "# def show_least_similar_using_C_all_classes(estimator, class_names, filenames_dict):  \n",
    "#     # Recolectar todas las comparaciones en una lista  \n",
    "#     all_comparisons = []  \n",
    "#     atypical_samples = []  \n",
    "\n",
    "#     for class_intent in range(len(class_names)):  \n",
    "#         class_name = class_names[class_intent]  \n",
    "\n",
    "#         # Obtener la matriz de similitud de las muestras dentro de la clase  \n",
    "#         C = estimator.C[class_intent]  \n",
    "\n",
    "#         # Ordenar los índices según las similitudes (de menor a mayor)  \n",
    "#         least_similar_indices = np.argsort(C, axis=None)  \n",
    "\n",
    "#         shown_pairs = set()  \n",
    "#         count = 0  \n",
    "#         show_samples = 100  # Cambiar para capturar las primeras 100 comparaciones  \n",
    "\n",
    "#         participation_count = {}  \n",
    "\n",
    "#         for idx in least_similar_indices:  \n",
    "#             if count >= show_samples:  \n",
    "#                 break  \n",
    "\n",
    "#             idx_2d = np.unravel_index(idx, C.shape)  \n",
    "\n",
    "#             if idx_2d[0] == idx_2d[1]:  \n",
    "#                 continue  \n",
    "\n",
    "#             index_pair = tuple(sorted((idx_2d[0], idx_2d[1])))  \n",
    "#             if index_pair in shown_pairs:  \n",
    "#                 continue  \n",
    "\n",
    "#             shown_pairs.add(index_pair)  \n",
    "\n",
    "#             participation_count[idx_2d[0]] = participation_count.get(idx_2d[0], 0) + 1  \n",
    "#             participation_count[idx_2d[1]] = participation_count.get(idx_2d[1], 0) + 1  \n",
    "\n",
    "#             # Obtener los índices de las muestras en el dataset  \n",
    "#             source_idx = estimator.class_indices[class_intent][idx_2d[0]]  \n",
    "#             target_idx = estimator.class_indices[class_intent][idx_2d[1]]  \n",
    "\n",
    "#             if source_idx < len(filenames_dict) and target_idx < len(filenames_dict):  \n",
    "#                 source_filename = Path(filenames_dict[int(source_idx)])  \n",
    "#                 target_filename = Path(filenames_dict[int(target_idx)])  \n",
    "\n",
    "#                 value = C[idx_2d]  \n",
    "\n",
    "#                 # Agrega los detalles a la lista de comparaciones  \n",
    "#                 all_comparisons.append(  \n",
    "#                     (class_name, source_filename.name, target_filename.name, value)  \n",
    "#                 )  \n",
    "\n",
    "#                 count += 1  \n",
    "\n",
    "#         # Encontrar las muestras más atípicas  \n",
    "#         most_atypical = sorted(participation_count.items(), key=lambda x: -x[1])  \n",
    "\n",
    "#         # Agregar las 10 más atípicas a la lista  \n",
    "#         for rank, (img_idx, freq) in enumerate(most_atypical[:10], 1):  \n",
    "#             img_name = Path(filenames_dict[int(estimator.class_indices[class_intent][img_idx])]).name  \n",
    "#             atypical_samples.append((class_name, img_name, freq))  \n",
    "\n",
    "#     # Exportar comparaciones a CSV  \n",
    "#     with open(\"least_similar_comparisons_MNIST.csv\", mode=\"w\", newline=\"\") as csv_file:  \n",
    "#         writer = csv.writer(csv_file)  \n",
    "#         writer.writerow([\"Class Name\", \"Source Image\", \"Target Image\", \"Similarity\"])  \n",
    "#         writer.writerows(all_comparisons)  \n",
    "\n",
    "#     # Exportar muestras atípicas a CSV  \n",
    "#     with open(\"atypical_samples_MNIST.csv\", mode=\"w\", newline=\"\") as csv_file:  \n",
    "#         writer = csv.writer(csv_file)  \n",
    "#         writer.writerow([\"Class Name\", \"Image Name\", \"Frequency\"])  \n",
    "#         writer.writerows(atypical_samples)  \n",
    "\n",
    "#     # Exportar comparaciones a TXT  \n",
    "#     with open(\"least_similar_comparisons_MNIST.txt\", mode=\"w\") as txt_file:  \n",
    "#         for class_name, source_fname, target_fname, value in all_comparisons:  \n",
    "#             txt_file.write(  \n",
    "#                 f\"Clase: {class_name}, {source_fname} vs {target_fname}, Similitud: {value:.4f}\\n\"  \n",
    "#             )  \n",
    "\n",
    "#     # Exportar muestras atípicas a TXT  \n",
    "#     with open(\"atypical_samples_MNIST.txt\", mode=\"w\") as txt_file:  \n",
    "#         for class_name, img_name, freq in atypical_samples:  \n",
    "#             txt_file.write(  \n",
    "#                 f\"Clase: {class_name}, Imagen: {img_name}, Frecuencia: {freq}\\n\"  \n",
    "#             )  \n",
    "\n",
    "# print(\"Exporting comparisons and atypical samples to CSV and TXT...\")  \n",
    "# show_least_similar_using_C_all_classes(estimator, class_names_train, filenames_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizar promedios de las muestras menos similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para encontrar y mostrar las imágenes menos similares dentro de cada clase usando la matriz C  \n",
    "def show_least_similar_avg_using_C_all_classes(estimator, class_names, filenames_dict, num_samples_to_show=2):  \n",
    "    images_to_show = []  # Lista para almacenar las imágenes y sus detalles  \n",
    "\n",
    "    # Recorre las clases y genera la lista de descripciones  \n",
    "    for class_intent in range(len(class_names)):  \n",
    "        class_name = class_names[class_intent]  \n",
    "        print(f\"\\nClase: {class_name}\")  \n",
    "\n",
    "        # Obtener la matriz de similitud de las muestras dentro de la clase  \n",
    "        C = estimator.C[class_intent]  \n",
    "\n",
    "        # Imprimir la forma de la matriz de similitud de la clase  \n",
    "        print(f\"Forma de la matriz de la clase {class_name}: {C.shape}\")  \n",
    "\n",
    "        # Calcular el promedio de similitud para cada muestra  \n",
    "        avg_similarity_per_sample = np.mean(C, axis=1)  \n",
    "\n",
    "        # Ordenar las muestras por su promedio de similitud (de menor a mayor)  \n",
    "        sorted_indices = np.argsort(avg_similarity_per_sample)  \n",
    "\n",
    "        # Mostrar las imágenes de las muestras con menor promedio de similitud  \n",
    "        for idx in sorted_indices[:num_samples_to_show]:  \n",
    "            avg_sim = avg_similarity_per_sample[idx]  \n",
    "\n",
    "            # Obtener los índices de las muestras en el dataset  \n",
    "            source_idx = estimator.class_indices[class_intent][idx]  \n",
    "\n",
    "            # Verificar que los índices estén dentro de los límites del dataset  \n",
    "            if source_idx < len(filenames_dict):  \n",
    "                source_filename = Path(filenames_dict[source_idx])  \n",
    "            \n",
    "                \n",
    "                # Formatear y mostrar la salida  \n",
    "                print(f\"\\tMuestra: {source_filename.name} ({class_name}), Promedio de Similitud: {avg_sim:.4f}\")  \n",
    "\n",
    "                # Agrega los detalles a la lista para visualización  \n",
    "                images_to_show.append((source_filename, class_name, avg_sim))  \n",
    "        \n",
    "\n",
    "    # Luego, realiza la visualización de las imágenes  \n",
    "    for source_filename, class_name, avg_sim in images_to_show:  \n",
    "        img_source = plt.imread(source_filename)  \n",
    "\n",
    "        plt.figure(figsize=(3, 3))  \n",
    "        plt.imshow(img_source)  \n",
    "        plt.title(f\"{class_name}: \\n{source_filename.name}\\nPromedio de Similitud: {avg_sim:.4f}\", fontsize=8)  \n",
    "        plt.axis('off')  # Elimina los ejes para centrar la atención en la imagen  \n",
    "        plt.show()  \n",
    "\n",
    "print(\"Muestras con menor valor de promedio de similitud:\\n\") \n",
    "num_samples_to_show = 2  # Número de muestras para visualizar por clase  \n",
    "show_least_similar_avg_using_C_all_classes(estimator, class_names_train, filenames_dict, num_samples_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imagenes menos similares a la muestra especifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Función para encontrar y mostrar los detalles de similitud de una imagen específica  \n",
    "def show_image_similarity_details(estimator, class_names, filenames_dict, target_image_name, num_least_similar=10):  \n",
    "    # Variable para almacenar el resultado  \n",
    "    result = None  \n",
    "\n",
    "    # Recorre las clases y busca la imagen objetivo  \n",
    "    for class_intent in range(len(class_names)):  \n",
    "        class_name = class_names[class_intent]  \n",
    "\n",
    "        # Obtener la matriz de similitud de las muestras dentro de la clase  \n",
    "        C = estimator.C[class_intent]  \n",
    "\n",
    "        # Calcular el promedio de similitud para cada muestra  \n",
    "        avg_similarity_per_sample = np.mean(C, axis=1)  \n",
    "\n",
    "        # Buscar el índice de la imagen objetivo en la clase actual  \n",
    "        for idx, source_idx in enumerate(estimator.class_indices[class_intent]):  \n",
    "            source_filename = Path(filenames_dict[source_idx]).name  \n",
    "            if source_filename == target_image_name:  \n",
    "                # Encontrar el promedio de similitud y la posición  \n",
    "                avg_sim = avg_similarity_per_sample[idx]  \n",
    "                sorted_indices = np.argsort(avg_similarity_per_sample)  \n",
    "                position = np.where(sorted_indices == idx)[0][0] + 1  # +1 para posición 1-indexada  \n",
    "\n",
    "                # Guardar el resultado  \n",
    "                result = (class_name, avg_sim, position, len(avg_similarity_per_sample), source_filename, idx)  \n",
    "                break  \n",
    "\n",
    "        if result:  \n",
    "            break  \n",
    "\n",
    "    if result:  \n",
    "        class_name, avg_sim, position, total_samples, source_filename, target_idx = result  \n",
    "        print(f\"\\nImagen: {target_image_name} (Clase: {class_name})\")  \n",
    "        print(f\"Promedio de Similitud: {avg_sim:.4f}\")  \n",
    "        print(f\"Posición: {position} de {total_samples}\")  \n",
    "\n",
    "        # Mostrar la imagen objetivo  \n",
    "        img_source = plt.imread(Path(filenames_dict[source_idx]))  \n",
    "        plt.figure(figsize=(3, 3))  \n",
    "        plt.imshow(img_source)  \n",
    "        plt.title(f\"{class_name}: {source_filename}\\nPromedio de Similitud: {avg_sim:.4f}\\nPosición: {position}/{total_samples}\", fontsize=8)  \n",
    "        plt.axis('off')  \n",
    "        plt.show()  \n",
    "\n",
    "        # Mostrar las imágenes menos similares a la imagen objetivo  \n",
    "        print(f\"\\nLas {num_least_similar} imágenes menos similares a {target_image_name}\\n:\")  \n",
    "\n",
    "        # Obtener las similitudes de la imagen objetivo con todas las demás  \n",
    "        similarities = C[target_idx]  \n",
    "\n",
    "        # Ordenar las similitudes de menor a mayor  \n",
    "        least_similar_indices = np.argsort(similarities)[:num_least_similar]  \n",
    "\n",
    "        for i, idx in enumerate(least_similar_indices):  \n",
    "            least_sim = similarities[idx]  \n",
    "            least_sim_idx = estimator.class_indices[class_intent][idx]  \n",
    "            least_sim_filename = Path(filenames_dict[least_sim_idx]).name  \n",
    "\n",
    "            print(f\"\\t{i+1}. Imagen: {least_sim_filename} (Clase: {class_name}), Similitud: {least_sim:.4f}\")\n",
    "\n",
    "            # Mostrar la imagen menos similar  \n",
    "            img_least_sim = plt.imread(Path(filenames_dict[least_sim_idx]))  \n",
    "            plt.figure(figsize=(3, 3))  \n",
    "            plt.imshow(img_least_sim)  \n",
    "            plt.title(f\"{class_name}: {least_sim_filename}\\nSimilitud: {least_sim:.4f}\", fontsize=8)  \n",
    "            plt.axis('off')  \n",
    "            plt.show()  \n",
    "  \n",
    "\n",
    "    else:  \n",
    "        print(f\"\\nImagen {target_image_name} no encontrada en las clases proporcionadas.\")  \n",
    "\n",
    "# Ejemplo de uso  \n",
    "target_image_name = \"47797.png\"  # Cambia esto al nombre de la imagen que deseas buscar  \n",
    "num_least_similar = 10  # Número de imágenes menos similares a mostrar  \n",
    "show_image_similarity_details(estimator, class_names_train, filenames_dict, target_image_name, num_least_similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imagenes mas similares a la muestra especifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para encontrar y mostrar los detalles de similitud de una imagen específica  \n",
    "def show_image_similarity_details(estimator, class_names, filenames_dict, target_image_name, num_most_similar=10):  \n",
    "    # Variable para almacenar el resultado  \n",
    "    result = None  \n",
    "\n",
    "    # Recorre las clases y busca la imagen objetivo  \n",
    "    for class_intent in range(len(class_names)):  \n",
    "        class_name = class_names[class_intent]  \n",
    "\n",
    "        # Obtener la matriz de similitud de las muestras dentro de la clase  \n",
    "        C = estimator.C[class_intent]  \n",
    "\n",
    "        # Calcular el promedio de similitud para cada muestra  \n",
    "        avg_similarity_per_sample = np.mean(C, axis=1)  \n",
    "\n",
    "        # Buscar el índice de la imagen objetivo en la clase actual  \n",
    "        for idx, source_idx in enumerate(estimator.class_indices[class_intent]):  \n",
    "            source_filename = Path(filenames_dict[source_idx]).name  \n",
    "            if source_filename == target_image_name:  \n",
    "                # Encontrar el promedio de similitud y la posición  \n",
    "                avg_sim = avg_similarity_per_sample[idx]  \n",
    "                sorted_indices = np.argsort(avg_similarity_per_sample)  \n",
    "                position = np.where(sorted_indices == idx)[0][0] + 1  # +1 para posición 1-indexada  \n",
    "\n",
    "                # Guardar el resultado  \n",
    "                result = (class_name, avg_sim, position, len(avg_similarity_per_sample), source_filename, idx)  \n",
    "                break  \n",
    "\n",
    "        if result:  \n",
    "            break  \n",
    "\n",
    "    if result:  \n",
    "        class_name, avg_sim, position, total_samples, source_filename, target_idx = result  \n",
    "        print(f\"\\nImagen: {target_image_name} (Clase: {class_name})\")  \n",
    "        print(f\"Promedio de Similitud: {avg_sim:.4f}\")  \n",
    "        print(f\"Posición: {position} de {total_samples}\")  \n",
    "\n",
    "        # Mostrar la imagen objetivo  \n",
    "        img_source = plt.imread(Path(filenames_dict[source_idx]))  \n",
    "        plt.figure(figsize=(3, 3))  \n",
    "        plt.imshow(img_source)  \n",
    "        plt.title(f\"{class_name}: {source_filename}\\nPromedio de Similitud: {avg_sim:.4f}\\nPosición: {position}/{total_samples}\", fontsize=8)  \n",
    "        plt.axis('off')  \n",
    "        plt.show()  \n",
    "\n",
    "        # Mostrar las imágenes más similares a la imagen objetivo  \n",
    "        print(f\"\\nLas {num_most_similar} imágenes más similares a {target_image_name}\\n:\")  \n",
    "\n",
    "        # Obtener las similitudes de la imagen objetivo con todas las demás  \n",
    "        similarities = C[target_idx]  \n",
    "\n",
    "        # Ordenar las similitudes de mayor a menor  \n",
    "        most_similar_indices = np.argsort(similarities)[-num_most_similar-1:-1][::-1]  # Excluding self and reversing order  \n",
    "\n",
    "        for i, idx in enumerate(most_similar_indices):  \n",
    "            most_sim = similarities[idx]  \n",
    "            most_sim_idx = estimator.class_indices[class_intent][idx]  \n",
    "            most_sim_filename = Path(filenames_dict[most_sim_idx]).name  \n",
    "\n",
    "            print(f\"\\t{i+1}. Imagen: {most_sim_filename} (Clase: {class_name}), Similitud: {most_sim:.4f}\")\n",
    "            \n",
    "            # Mostrar la imagen más similar  \n",
    "            img_most_sim = plt.imread(Path(filenames_dict[most_sim_idx]))  \n",
    "            plt.figure(figsize=(3, 3))  \n",
    "            plt.imshow(img_most_sim)  \n",
    "            plt.title(f\"{class_name}: {most_sim_filename}\\nSimilitud: {most_sim:.4f}\", fontsize=8)  \n",
    "            plt.axis('off')  \n",
    "            plt.show()  \n",
    "  \n",
    "\n",
    "    else:  \n",
    "        print(f\"\\nImagen {target_image_name} no encontrada en las clases proporcionadas.\")  \n",
    "\n",
    "# Ejemplo de uso  \n",
    "target_image_name = \"58944.png\"  # Cambia esto al nombre de la imagen que deseas buscar  \n",
    "num_most_similar = 10  # Número de imágenes más similares a mostrar  \n",
    "show_image_similarity_details(estimator, class_names_train, filenames_dict, target_image_name, num_most_similar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
