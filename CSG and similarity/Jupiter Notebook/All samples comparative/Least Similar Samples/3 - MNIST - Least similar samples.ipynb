{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from new_spectral_metric.new_estimator_all_samples import CumulativeGradientEstimator_All_samples\n",
    "from new_spectral_metric.new_visualize import make_graph\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, Dense, MaxPooling2D, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET DESDE DIRECTORIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de dataset\n",
    "\n",
    "directorio_dataset = ('../../../Datasets/MNIST')\n",
    "directorio_dataset = pathlib.Path(directorio_dataset)\n",
    "\n",
    "# Lectura de la carpeta train\n",
    "directorio_train = ('../../../Datasets/MNIST/train')\n",
    "directorio_train = pathlib.Path(directorio_train)\n",
    "\n",
    "# Lectura de la carpeta test\n",
    "directorio_test = ('../../../Datasets/MNIST/test')\n",
    "directorio_test = pathlib.Path(directorio_test)\n",
    "\n",
    "total_dataset = len(list(directorio_dataset.glob('*/*/*.png')))  # Cuenta la cantidad de imagenes del dataset (Aqui busca en las subcarpetas del directorio del dataset)\n",
    "total_train = len(list(directorio_train.glob('*/*.png')))  # Cuenta la cantidad de imagenes de train\n",
    "total_test = len(list(directorio_test.glob('*/*.png')))  # Cuenta la cantidad de imagenes de test\n",
    "\n",
    "print(f\"Total imagenes dataset: {total_dataset}\")\n",
    "print(f\"Total imagenes train: {total_train}\")\n",
    "print(f\"Total imagenes test: {total_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el batchsize del dataset completo\n",
    "batch_size_total = total_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de imagen y tamaño de batch en train\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "#batch_size = 32\n",
    "batch_size_train = total_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "# Data splitting (entrenamiento y validación)\n",
    "train_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  directorio_train,\n",
    "  #validation_split=0.2,\n",
    "  color_mode='rgb',\n",
    "  label_mode='int',\n",
    "  #subset=\"training\",\n",
    "  #seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de imagen y tamaño de batch en test\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "#batch_size = 32\n",
    "batch_size_test = total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (entrenamiento y validación)\n",
    "test_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  directorio_test,\n",
    "  #validation_split=0.2,\n",
    "  color_mode='rgb',\n",
    "  label_mode='int',\n",
    "  #subset=\"training\",\n",
    "  #seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el total de imágenes por clase en train y test  \n",
    "class_counts_total = {p.name: len(list(p.glob('*.png'))) for p in directorio_dataset.glob('*/*')}  \n",
    "class_counts_train = {p.name: len(list(p.glob('*.png'))) for p in directorio_train.glob('*')}  \n",
    "class_counts_test = {p.name: len(list(p.glob('*.png'))) for p in directorio_test.glob('*')}  \n",
    "\n",
    "# Encontrar el valor más bajo de imágenes por clase en train  \n",
    "menor_train = min(class_counts_train.values()) if class_counts_train else None  # Se almacena el valor de la clase que menos muestras tiene\n",
    "\n",
    "# Encontrar el valor más alto de imágenes por clase en train  \n",
    "mayor_train = max(class_counts_train.values()) if class_counts_train else None  # Se almacena el valor de la clase que mas muestras tiene\n",
    "\n",
    "\n",
    "# Encontrar el valor más bajo de imágenes por clase en test  \n",
    "menor_test = min(class_counts_test.values()) if class_counts_test else None  # Se almacena el valor de la clase que menos muestras tiene\n",
    "\n",
    "# Encontrar el valor más alto de imágenes por clase en test  \n",
    "mayor_test = max(class_counts_test.values()) if class_counts_test else None  # Se almacena el valor de la clase que mas muestras tiene\n",
    "\n",
    "\n",
    "# Mostrar el total de imágenes por clase en train  \n",
    "print(\"\\nTotal images per class in train:\")  \n",
    "for class_name, count in class_counts_train.items():  \n",
    "    print(f\"Class: {class_name}, Number of images: {count}\")  \n",
    "print(f\"Total images train: {sum(class_counts_train.values())}\")  \n",
    "\n",
    "# Mostrar el valor más bajo en train  \n",
    "print(f\"Fewer number of images in train: {menor_train}\")  \n",
    "\n",
    "# Mostrar el valor más alto en train  \n",
    "print(f\"Higher number of images in train: {mayor_train}\")  \n",
    "\n",
    "# Mostrar el total de imágenes por clase en test  \n",
    "print(\"\\nTotal images per class in test:\")  \n",
    "for class_name, count in class_counts_test.items():  \n",
    "    print(f\"Class: {class_name}, Number of images: {count}\")  \n",
    "print(f\"Total images test: {sum(class_counts_test.values())}\")  \n",
    "\n",
    "# Mostrar el valor más bajo en test  \n",
    "print(f\"Fewer images in test: {menor_test}\")\n",
    "\n",
    "# Mostrar el valor más alto en test  \n",
    "print(f\"Higher number of images in test: {mayor_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las clases\n",
    "class_names_train = list(class_counts_train.keys())\n",
    "class_names_test = list(class_counts_test.keys())\n",
    "#class_names_total = sorted(list(set(class_names_train + class_names_test)))\n",
    "class_names_total = list(class_counts_total.keys())\n",
    "\n",
    "# Mostrar el número de clases y los nombres\n",
    "print(f\"\\nNúmero de clases en train: {len(class_names_train)}\")\n",
    "print(f\"Nombres de las clases en train: {class_names_train}\")\n",
    "\n",
    "print(f\"\\nNúmero de clases en test: {len(class_names_test)}\")\n",
    "print(f\"Nombres de las clases en test: {class_names_test}\")\n",
    "\n",
    "print(f\"\\nNúmero total de clases en el dataset: {len(class_names_total)}\")   # Este valor cambia si el nombre de las clases es diferente\n",
    "print(f\"Nombres de todas las clases en el dataset: {class_names_total}\")     # Este valor tambien cambia si el nombre de las clases es diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels0 in train_images.take(1):  # only take first element of dataset\n",
    "    numpy_all_images = images.numpy()  # convertir el tensor de imágenes en un arreglo de numpy y ahora contiene las imágenes del conjunto de datos en formato de numpy.\n",
    "    numpy_all_labels = labels0.numpy()  # convierte el tensor de etiquetas en un arreglo de numpy y ahora contiene las etiquetas del conjunto de datos en formato de numpy\n",
    "\n",
    "numpy_all_images /= 255.0  # Scale the features to the [0, 1] range\n",
    "print(numpy_all_images.shape)\n",
    "\n",
    "# CIFAR-10 \n",
    "fully_dataset_train = numpy_all_images.reshape((numpy_all_images.shape[0], numpy_all_images.shape[1]*numpy_all_images.shape[2]*numpy_all_images.shape[3])) # es un arreglo bidimensional donde cada fila representa una imagen y cada columna representa un píxel de la imagen\n",
    "fully_labels_train = numpy_all_labels.reshape(numpy_all_labels.shape[0],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset complexity using CSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = CumulativeGradientEstimator_All_samples(M_sample=mayor_train, k_nearest=10)  # Utiliza el numero menor de muestras encontrado en cada clase dependiendo si es train o test\n",
    "estimator.fit(data=fully_dataset_train, target=fully_labels_train)\n",
    "csg = estimator.csg  # The actual complexity values.\n",
    "estimator.evals, estimator.evecs  # The eigenvalues and vectors.\n",
    "\n",
    "make_graph(estimator.difference, title=\"Dataset Complexity - MNIST: \"+str(csg), classes=class_names_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular la similitud entre clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "\n",
    "# Calcular la entropía por clase  \n",
    "entropy_per_class = entropy(estimator.W / estimator.W.sum(-1)[:, None], axis=-1)  \n",
    "\n",
    "# Encontrar la clase menos confusa (menor entropía)  \n",
    "least_confused_class_index = np.argmin(entropy_per_class)  \n",
    "least_confused_class_name = class_names_train[least_confused_class_index]  \n",
    "\n",
    "print(\"Class that is the least confused (lowest entropy):\", least_confused_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener los índices de los pares menos similares  \n",
    "pairs = list(zip(*np.unravel_index(np.argsort(estimator.W, axis=None), estimator.W.shape)))  \n",
    "\n",
    "# Filtrar pares donde i != j para evitar pares de la misma clase  \n",
    "pairs = [(i, j) for i, j in pairs if i != j]  \n",
    "\n",
    "print(\"Least similar pairs\")  \n",
    "lst = []  \n",
    "seen_pairs = set()  \n",
    "\n",
    "# Iterar sobre los primeros 10 pares menos similares  \n",
    "for i, j in pairs:  \n",
    "    # Verificar si el par o su inverso ya ha sido visto  \n",
    "    if (i, j) not in seen_pairs and (j, i) not in seen_pairs:  \n",
    "        lst.append({\"Intent pair\": f\"{class_names_train[i]} <> {class_names_train[j]}\", \"Similarity\": estimator.W[i, j]})  \n",
    "        seen_pairs.add((i, j))  \n",
    "        seen_pairs.add((j, i))  \n",
    "    \n",
    "    # Detenerse después de encontrar 10 pares únicos  \n",
    "    if len(lst) == 10:  \n",
    "        break  \n",
    "\n",
    "# Mostrar los resultados en un DataFrame  \n",
    "print(pd.DataFrame(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener los nombres de las imagenes en train o test (dependiendo de lo que se quiera probar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los nombres de archivo en el dataset\n",
    "filenames = [str(f) for f in directorio_train.glob('*/*.png')]\n",
    "\n",
    "# Crear un mapeo de índices a rutas completas de archivo  \n",
    "filenames_dict = {i: str(f) for i, f in enumerate(directorio_train.glob('*/*.png'))} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular la similitud entre muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para encontrar y mostrar las imágenes menos similares usando la matriz M  \n",
    "def show_least_similar_using_M(estimator, filenames_dict):  \n",
    "    images_to_show = []  # Lista para almacenar las imágenes y sus detalles  \n",
    "\n",
    "    # Obtener la matriz de similitud global (M)  \n",
    "    M = estimator.M  \n",
    "\n",
    "    # Imprimir la forma de la matriz de similitud  \n",
    "    print(f\"Forma de la matriz M: {M.shape}\")  \n",
    "\n",
    "    # Ordenar los índices según las similitudes (de menor a mayor)  \n",
    "    least_similar_indices = np.argsort(M, axis=None)  \n",
    "\n",
    "    shown_pairs = set()  # Para rastrear los pares de índices ya mostrados  \n",
    "    count = 0  \n",
    "    show_samples = 20  # Número de muestras para visualizar la similitud  \n",
    "\n",
    "    # Diccionario para contar la participación de cada imagen  \n",
    "    participation_count = {}  \n",
    "\n",
    "    for idx in least_similar_indices:  \n",
    "        if count >= show_samples:  \n",
    "            break  \n",
    "\n",
    "        # Convertir el índice plano a índice 2D  \n",
    "        idx_2d = np.unravel_index(idx, M.shape)  \n",
    "\n",
    "        # Saltar las comparaciones de una muestra consigo misma  \n",
    "        if idx_2d[0] == idx_2d[1]:  \n",
    "            continue  \n",
    "\n",
    "        # Crear un par ordenado de índices para prevenir duplicados  \n",
    "        index_pair = tuple(sorted((idx_2d[0], idx_2d[1])))  \n",
    "\n",
    "        # Verificamos si el par ya fue mostrado  \n",
    "        if index_pair in shown_pairs:  \n",
    "            continue  \n",
    "\n",
    "        shown_pairs.add(index_pair)  \n",
    "\n",
    "        # Actualizar el conteo de participación  \n",
    "        participation_count[idx_2d[0]] = participation_count.get(idx_2d[0], 0) + 1  \n",
    "        participation_count[idx_2d[1]] = participation_count.get(idx_2d[1], 0) + 1  \n",
    "\n",
    "        # Verificar que los índices estén dentro de los límites del dataset  \n",
    "        if idx_2d[0] < len(filenames_dict) and idx_2d[1] < len(filenames_dict):  \n",
    "            source_filename = Path(filenames_dict[int(idx_2d[0])])  \n",
    "            target_filename = Path(filenames_dict[int(idx_2d[1])])  \n",
    "\n",
    "            value = M[idx_2d]  \n",
    "\n",
    "            # Formatear y mostrar la salida  \n",
    "            print(f\"{source_filename.name} vs {target_filename.name}, Similitud: {value:.4f}\")  \n",
    "\n",
    "            # Agrega los detalles a la lista para visualización  \n",
    "            images_to_show.append((source_filename, target_filename, value))  \n",
    "\n",
    "            count += 1  \n",
    "\n",
    "    # Encontrar las muestras más atípicas  \n",
    "    most_atypical = sorted(participation_count.items(), key=lambda x: -x[1])  \n",
    "\n",
    "    # Mostrar las 10 más atípicas  \n",
    "    print(\"\\nMuestras más atípicas del dataset:\")  \n",
    "    for rank, (img_idx, freq) in enumerate(most_atypical[:10], 1):  \n",
    "        img_name = Path(filenames_dict[int(img_idx)]).name  \n",
    "        print(f\"\\t#{rank}: {img_name} con {freq} apariciones\")  \n",
    "    print(\"\\n\")  \n",
    "\n",
    "    # Luego, realiza la visualización de las imágenes  \n",
    "    for source_filename, target_filename, value in images_to_show:  \n",
    "        img_source = plt.imread(source_filename)  \n",
    "        img_target = plt.imread(target_filename)  \n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(5, 3))  \n",
    "        axs[0].imshow(img_source)  \n",
    "        axs[0].set_title(f\"{source_filename.name}\", fontsize=8)  \n",
    "        axs[0].axis('off')  # Elimina los ejes para centrar la atención en la imagen  \n",
    "\n",
    "        axs[1].imshow(img_target)  \n",
    "        axs[1].set_title(f\"{target_filename.name}\", fontsize=8)  \n",
    "        axs[1].axis('off')  \n",
    "        plt.suptitle(f\"Similarity: {value:.4f}\")  \n",
    "        plt.subplots_adjust(wspace=0.3, hspace=0.3)  # Ajusta el espacio entre subtramas  \n",
    "        plt.show()  \n",
    "\n",
    "\n",
    "print(\"Muestras menos similares entre todas las imágenes del dataset \\n\")  \n",
    "show_least_similar_using_M(estimator, filenames_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
