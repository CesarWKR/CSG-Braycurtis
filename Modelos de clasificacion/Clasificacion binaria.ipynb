{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "import torchvision.transforms as transforms  \n",
    "from torchvision.datasets import ImageFolder  \n",
    "from PIL import Image  \n",
    "import pathlib  \n",
    "import cupy as cp \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# Verificar la disponibilidad de la GPU  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "print(\"Nombre de la GPU:\", torch.cuda.get_device_name() if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes dataset: 10000\n",
      "Total imágenes originales: 5000\n",
      "Total imágenes corruptas: 5000\n"
     ]
    }
   ],
   "source": [
    "# Definir directorios\n",
    "directorio_dataset = '../Datasets/CIFAR-10 dos clases'\n",
    "imagenes_originales = '../Datasets/CIFAR-10 dos clases/cat'\n",
    "imagenes_corruptas = '../Datasets/CIFAR-10 dos clases/cat_c_defocus_blur'\n",
    "\n",
    "directorio_dataset = pathlib.Path(directorio_dataset)\n",
    "imagenes_originales = pathlib.Path(imagenes_originales)\n",
    "imagenes_corruptas = pathlib.Path(imagenes_corruptas)\n",
    "\n",
    "\n",
    "\n",
    "# Dimensiones de imagen y tamaño de batch\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "#batch_size = len(list(data_dir.glob('*/*.png'))) # leer todas las imágenes al tiempo\n",
    "\n",
    "\n",
    "# Transformaciones para preprocesamiento de datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),  # Ajustar tamaño a 32x32\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = pathlib.Path(directory)\n",
    "        self.transform = transform\n",
    "        self.images = list(self.directory.glob('*.png'))\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.images)  \n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        img_path = self.images[idx]  \n",
    "        image = Image.open(img_path).convert('RGB')  \n",
    "        if self.transform:  \n",
    "            image = self.transform(image)  \n",
    "        return image\n",
    "\n",
    "\n",
    "# Crear datasets personalizados\n",
    "dataset_completo = datasets.ImageFolder(root=directorio_dataset, transform=transform)\n",
    "dataset_originales = CustomImageDataset(imagenes_originales, transform=transform)\n",
    "dataset_corruptas = CustomImageDataset(imagenes_corruptas, transform=transform)\n",
    "\n",
    "# Calcular totales\n",
    "total_dataset = len(dataset_originales) + len(dataset_corruptas)\n",
    "total_originales = len(dataset_originales)\n",
    "total_corruptas = len(dataset_corruptas)\n",
    "\n",
    "batch_size = total_dataset\n",
    "\n",
    "\n",
    "\n",
    "# Crear el DataLoader para iterar sobre los datos en lotes\n",
    "# DataLoader para cargar los datasets\n",
    "dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "dataloader_originales = DataLoader(dataset_originales, batch_size=batch_size, shuffle=False)\n",
    "dataloader_corruptas = DataLoader(dataset_corruptas, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # DataLoader para cargar los datasets  \n",
    "# dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size, shuffle=False, num_workers=0)  \n",
    "\n",
    "print(f\"Total imágenes dataset: {total_dataset}\")  \n",
    "print(f\"Total imágenes originales: {total_originales}\")  \n",
    "print(f\"Total imágenes corruptas: {total_corruptas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 32\n",
    "img_width = 32\n",
    "batch_s = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(channels):\n",
    "    if channels == 3:\n",
    "        # Definir transformaciones para el conjunto de datos en escala a color\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((img_height, img_width)),  # Ajustar tamaño\n",
    "            transforms.ToTensor(),  # Convertir a tensor\n",
    "            transforms.Normalize((0.5,), (0.5,))  # Normalizar\n",
    "        ])\n",
    "    elif channels == 1:\n",
    "        # Definir transformaciones para el conjunto de datos en escala de grises\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),  # Convertir a escala de grises\n",
    "            transforms.Resize((img_height, img_width)),  # Ajustar tamaño\n",
    "            transforms.ToTensor(),  # Convertir a tensor\n",
    "            transforms.Normalize((0.5,), (0.5,))  # Normalizar\n",
    "        ])\n",
    "    else: \n",
    "        print(\"El valor elegido no está dentro del rango, por favor elija nuevamente\")\n",
    "        return None  # Devolver None en caso de elección inválida\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las transformaciones según la elección\n",
    "transform = get_transform(channels)\n",
    "\n",
    "# Crear datasets de entrenamiento y prueba desde el directorio\n",
    "if transform is not None:\n",
    "    train_dataset = datasets.ImageFolder(data_dir_train, transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(data_dir_test, transform=transform)\n",
    "else:\n",
    "    print(\"No se pueden crear los datasets debido a una elección inválida.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
