{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "import torchvision.transforms as transforms  \n",
    "from torchvision.datasets import ImageFolder  \n",
    "from PIL import Image  \n",
    "import pathlib  \n",
    "import cupy as cp \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# Verificar la disponibilidad de la GPU  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "print(\"Nombre de la GPU:\", torch.cuda.get_device_name() if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes dataset: 10000\n",
      "Total imágenes originales: 5000\n",
      "Total imágenes corruptas: 5000\n",
      "Número de clases: 2\n",
      "Los nombres de las clases son: ['cat', 'cat_c_defocus_blur']\n"
     ]
    }
   ],
   "source": [
    "# Definir directorios\n",
    "directorio_dataset = '../Datasets/CIFAR-10 dos clases'\n",
    "imagenes_originales = '../Datasets/CIFAR-10 dos clases/cat'\n",
    "imagenes_corruptas = '../Datasets/CIFAR-10 dos clases/cat_c_defocus_blur'\n",
    "\n",
    "directorio_dataset = pathlib.Path(directorio_dataset)\n",
    "imagenes_originales = pathlib.Path(imagenes_originales)\n",
    "imagenes_corruptas = pathlib.Path(imagenes_corruptas)\n",
    "\n",
    "\n",
    "# Images dimentions\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "channels = 3\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Transformaciones para preprocesamiento de datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),  # Ajustar tamaño a 32x32\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = pathlib.Path(directory)\n",
    "        self.transform = transform\n",
    "        self.images = list(self.directory.glob('*.png'))\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.images)  \n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        img_path = self.images[idx]  \n",
    "        image = Image.open(img_path).convert('RGB')  \n",
    "        if self.transform:  \n",
    "            image = self.transform(image)  \n",
    "        return image\n",
    "\n",
    "\n",
    "# Crear datasets personalizados\n",
    "dataset_completo = datasets.ImageFolder(root=directorio_dataset, transform=transform)\n",
    "dataset_originales = CustomImageDataset(imagenes_originales, transform=transform)\n",
    "dataset_corruptas = CustomImageDataset(imagenes_corruptas, transform=transform)\n",
    "\n",
    "# Calcular totales\n",
    "total_dataset = len(dataset_originales) + len(dataset_corruptas)\n",
    "total_originales = len(dataset_originales)\n",
    "total_corruptas = len(dataset_corruptas)\n",
    "\n",
    "\n",
    "# Crear el DataLoader para iterar sobre los datos en lotes\n",
    "# DataLoader para cargar los datasets\n",
    "dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "dataloader_originales = DataLoader(dataset_originales, batch_size=batch_size, shuffle=False)\n",
    "dataloader_corruptas = DataLoader(dataset_corruptas, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # DataLoader para cargar los datasets  \n",
    "# dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size, shuffle=False, num_workers=0)  \n",
    "\n",
    "print(f\"Total imágenes dataset: {total_dataset}\")  \n",
    "print(f\"Total imágenes originales: {total_originales}\")  \n",
    "print(f\"Total imágenes corruptas: {total_corruptas}\")\n",
    "\n",
    "class_names = dataset_completo.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Número de clases: {num_classes}\")\n",
    "print(f\"Los nombres de las clases son: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(channels):   # Aqui define los canales de entrada que se aplicaran al modelo\n",
    "    if channels == 3:\n",
    "        # Definir transformaciones para el conjunto de datos en escala a color\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((img_height, img_width)),  # Ajustar tamaño\n",
    "            transforms.ToTensor(),  # Convertir a tensor\n",
    "            transforms.Normalize((0.5,), (0.5,))  # Normalizar\n",
    "        ])\n",
    "    elif channels == 1:\n",
    "        # Definir transformaciones para el conjunto de datos en escala de grises\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),  # Convertir a escala de grises\n",
    "            transforms.Resize((img_height, img_width)),  # Ajustar tamaño\n",
    "            transforms.ToTensor(),  # Convertir a tensor\n",
    "            transforms.Normalize((0.5,), (0.5,))  # Normalizar\n",
    "        ])\n",
    "    else: \n",
    "        print(\"El valor elegido no está dentro del rango, por favor elija nuevamente\")\n",
    "        return None  # Devolver None en caso de elección inválida\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las transformaciones según la elección  \n",
    "transform = get_transform(channels)  \n",
    "\n",
    "# Crear el dataset completo con las transformaciones aplicadas  \n",
    "if transform is not None:  \n",
    "    train_dataset = datasets.ImageFolder(root=directorio_dataset, transform=transform)  # En train dataset se toma el dataset completo para entrenarlo\n",
    "else:  \n",
    "    print(\"No se puede crear el dataset debido a una elección inválida.\")  \n",
    "\n",
    "\n",
    "# Crear el DataLoader para iterar sobre el dataset completo  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5153\n",
      "Epoch [2/10], Loss: 0.2910\n",
      "Epoch [3/10], Loss: 0.4930\n",
      "Epoch [4/10], Loss: 0.4904\n",
      "Epoch [5/10], Loss: 0.2689\n",
      "Epoch [6/10], Loss: 0.0833\n",
      "Epoch [7/10], Loss: 0.1043\n",
      "Epoch [8/10], Loss: 0.1485\n",
      "Epoch [9/10], Loss: 0.0736\n",
      "Epoch [10/10], Loss: 0.0099\n",
      "Entrenamiento completado\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir el modelo de clasificación multiclase  \n",
    "class MulticlassCNN(nn.Module):  \n",
    "    def __init__(self, num_classes=2):  \n",
    "        super(MulticlassCNN, self).__init__()  \n",
    "        self.conv1 = nn.Conv2d(channels, 16, kernel_size=3, stride=1, padding=1)  \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)  \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  \n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)  \n",
    "        self.fc2 = nn.Linear(128, num_classes)  \n",
    "        self.relu = nn.ReLU()  \n",
    "\n",
    "    def forward(self, x):  \n",
    "        x = self.pool(self.relu(self.conv1(x)))  \n",
    "        x = self.pool(self.relu(self.conv2(x)))  \n",
    "        x = x.view(-1, 32 * 8 * 8)  \n",
    "        x = self.relu(self.fc1(x))  \n",
    "        x = self.fc2(x)  \n",
    "        return x  \n",
    "\n",
    "# Instanciar el modelo  \n",
    "model = MulticlassCNN(num_classes=num_classes).to(device)  \n",
    "\n",
    "# Definir la función de pérdida y el optimizador  \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "# Ejemplo de bucle de entrenamiento  \n",
    "num_epochs = 10  \n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()  # Asegurarse de que el modelo está en modo de entrenamiento  \n",
    "\n",
    "    running_loss = 0.0  \n",
    "    correct = 0  \n",
    "    total = 0  \n",
    "\n",
    "    for images, labels in train_loader:  \n",
    "        images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "        # Adelante  \n",
    "        outputs = model(images)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "\n",
    "        # Atrás y optimización  \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "        # Actualizar estadísticas  \n",
    "        running_loss += loss.item()  \n",
    "\n",
    "        # Calcular precisión  \n",
    "        _, predicted = torch.max(outputs, 1)  \n",
    "        total += labels.size(0)  \n",
    "        correct += (predicted == labels).sum().item()  \n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)  \n",
    "    accuracy = 100 * correct / total  \n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%\")  \n",
    "\n",
    "print(\"Entrenamiento completado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
