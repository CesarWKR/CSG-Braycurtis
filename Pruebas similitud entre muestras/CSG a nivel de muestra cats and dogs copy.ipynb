{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones  \n",
    "import numpy as np  \n",
    "import tensorflow as tf  \n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import Flatten, Conv2D, Dense, MaxPooling2D, Lambda  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  \n",
    "from pathlib import Path  \n",
    "import sys  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir el directorio raíz del proyecto a sys.path\n",
    "module_path = Path('/Users/Cesar/Desktop/Proyecto-CSG/').resolve()\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(str(module_path))\n",
    "\n",
    "# Añadir el directorio que contiene 'new_spectral_metric' a sys.path\n",
    "new_spectral_metric_path = module_path / '/Users/Cesar/Desktop/Proyecto-CSG/new_spectral_metric/'\n",
    "if new_spectral_metric_path not in sys.path:\n",
    "    sys.path.append(str(new_spectral_metric_path))\n",
    "\n",
    "from new_spectral_metric.new_estimator import CumulativeGradientEstimator  \n",
    "from new_spectral_metric.new_visualize import make_graph  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes: 696\n",
      "Total imágenes de gatos: 348\n",
      "Total imágenes de perros: 348\n"
     ]
    }
   ],
   "source": [
    "# Lectura de dataset\n",
    "\n",
    "# Configuración del directorio del dataset  \n",
    "dataset_dir = Path('../Datasets/Cats and dogs - train')  \n",
    "cats_dir = dataset_dir / 'cats'  \n",
    "dogs_dir = dataset_dir / 'dogs'  \n",
    "\n",
    "# Contar imágenes  \n",
    "total_images = sum(1 for _ in dataset_dir.glob('*/*.jpg'))  \n",
    "total_cats = sum(1 for _ in cats_dir.glob('*.jpg'))  \n",
    "total_dogs = sum(1 for _ in dogs_dir.glob('*.jpg'))  \n",
    "\n",
    "print(f\"Total imágenes: {total_images}\")  \n",
    "print(f\"Total imágenes de gatos: {total_cats}\")  \n",
    "print(f\"Total imágenes de perros: {total_dogs}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de la imagen y tamaño del batch  \n",
    "img_height = 32  \n",
    "img_width = 32 \n",
    "batch_size = total_images  # Configurar un batch size razonable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 696 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)  \n",
    "\n",
    "data_flow = datagen.flow_from_directory(  \n",
    "    dataset_dir,  \n",
    "    target_size=(img_height, img_width),  \n",
    "    batch_size=batch_size,  \n",
    "    class_mode='binary',  # Forma binaria ya que solamente tienes dos clases  \n",
    "    shuffle=False  # No mezclar si no es necesario para la tarea actual  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases: 2\n",
      "Los nombres de las clases son: dict_keys(['cats', 'dogs'])\n"
     ]
    }
   ],
   "source": [
    "# Obtener los nombres de las clases de los datos  \n",
    "class_names = data_flow.class_indices.keys()  \n",
    "num_classes = len(class_names)  \n",
    "print(f\"Número de clases: {num_classes}\")  \n",
    "print(f\"Los nombres de las clases son: {class_names}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convertir las imágenes a arrays numpy para visualización  \n",
    "images, labels = next(data_flow)  \n",
    "assert len(images) == batch_size  # Verifica el tamaño del batch  \n",
    "images /= 255.0  # Escala las características al rango [0, 1]  \n",
    "print(images.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos para CumulativeGradientEstimator  \n",
    "fully_dataset = images.reshape((images.shape[0], -1))  \n",
    "fully_labels = labels.reshape(labels.shape[0],) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Inicializar y ajustar el estimador  \u001b[39;00m\n\u001b[0;32m      2\u001b[0m estimator \u001b[38;5;241m=\u001b[39m CumulativeGradientEstimator(M_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m348\u001b[39m, k_nearest\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Ajusta parámetros si es necesario  \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfully_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfully_labels\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      4\u001b[0m csg \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mcsg  \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSG calculado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\new_spectral_metric\\new_estimator.py:32\u001b[0m, in \u001b[0;36mCumulativeGradientEstimator.fit\u001b[1;34m(self, data, target)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Pasar self.M_sample a find_samples\u001b[39;00m\n\u001b[0;32m     28\u001b[0m class_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_indices \u001b[38;5;241m=\u001b[39m find_samples(\n\u001b[0;32m     29\u001b[0m     data_x, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class, M\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM_sample\n\u001b[0;32m     30\u001b[0m )\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\new_spectral_metric\\new_estimator.py:36\u001b[0m, in \u001b[0;36mCumulativeGradientEstimator.compute\u001b[1;34m(self, data, target, class_samples)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, target, class_samples):\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_arrays \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_expectation_with_monte_carlo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_nearest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_nearest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class)\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m product(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class), \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class)):\n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\new_spectral_metric\\new_lib.py:31\u001b[0m, in \u001b[0;36mcompute_expectation_with_monte_carlo\u001b[1;34m(data, target, class_samples, class_indices, n_class, k_nearest, distance)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m     30\u001b[0m similarity_arrays: Dict[\u001b[38;5;28mint\u001b[39m, Dict[\u001b[38;5;28mint\u001b[39m, SimilarityArrays]] \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m expectation \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# S-matrix\u001b[39;00m\n\u001b[0;32m     33\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m k: np\u001b[38;5;241m.\u001b[39marray(pairwise_distances(class_samples[k], data, metric\u001b[38;5;241m=\u001b[39mdistance))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_ix \u001b[38;5;129;01min\u001b[39;00m class_samples:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# Inicializar y ajustar el estimador  \n",
    "estimator = CumulativeGradientEstimator(M_sample=348, k_nearest=10)  \n",
    "estimator.fit(data=fully_dataset, target=fully_labels)  \n",
    "csg = estimator.csg  \n",
    "print(f\"CSG calculado: {csg}\")  \n",
    "\n",
    "make_graph(estimator.difference, title=f\"Comparativa entre clases, CSG: {csg}\", classes=list(class_names))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculo de similitud entre clases\n",
      "  Clases a comparar  Similitud\n",
      "0      cats <> dogs   0.942377\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ordena los pares de clases en orden de similitud ascendente (menos similar primero)\n",
    "pairs = list(zip(*np.unravel_index(np.argsort(estimator.W, axis=None), estimator.W.shape)))\n",
    "pairs = [(original,corrupto) for original,corrupto in pairs if original != corrupto]\n",
    "\n",
    "similitud_de_clases = pairs[0]\n",
    "original, corrupto = similitud_de_clases  # Pares de clases menos similares\n",
    "\n",
    "print(\"Calculo de similitud entre clases\")\n",
    "lst = []\n",
    "for idx, (original,corrupto) in enumerate(pairs[::2][:1]):\n",
    "    lst.append({\"Clases a comparar\" : f\"{class_names[original]} <> {class_names[corrupto]}\", \"Similitud\": estimator.W[original,corrupto]})\n",
    "print(pd.DataFrame(lst))\n",
    "print(estimator.W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: ['cats', 'dogs'], Número de muestras: 348\n",
      "Clase: ['cats', 'dogs'], Número de muestras: 348\n"
     ]
    }
   ],
   "source": [
    "for class_name, indices in estimator.class_indices.items():\n",
    "    print(f\"Clase: {class_names}, Número de muestras: {len(indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats <> dogs\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0674\n",
      "\tNombre del archivo: cat_96.jpg, Clase: cats, Similitud: 0.1821\n",
      "\tNombre del archivo: cat_435.jpg, Clase: cats, Similitud: 0.1844\n",
      "\tNombre del archivo: cat_369.jpg, Clase: cats, Similitud: 0.1865\n",
      "\tNombre del archivo: cat_50.jpg, Clase: cats, Similitud: 0.1887\n",
      "\tNombre del archivo: cat_109.jpg, Clase: cats, Similitud: 0.2088\n",
      "\tNombre del archivo: cat_546.jpg, Clase: cats, Similitud: 0.2406\n",
      "\tNombre del archivo: cat_101.jpg, Clase: cats, Similitud: 0.2505\n",
      "\tNombre del archivo: cat_303.jpg, Clase: cats, Similitud: 0.2658\n",
      "\tNombre del archivo: cat_420.jpg, Clase: cats, Similitud: 0.3095\n",
      "dogs <> cats\n",
      "\tNombre del archivo: dog_403.jpg, Clase: dogs, Similitud: 0.0674\n",
      "\tNombre del archivo: dog_505.jpg, Clase: dogs, Similitud: 0.1821\n",
      "\tNombre del archivo: dog_197.jpg, Clase: dogs, Similitud: 0.1844\n",
      "\tNombre del archivo: dog_412.jpg, Clase: dogs, Similitud: 0.1865\n",
      "\tNombre del archivo: dog_344.jpg, Clase: dogs, Similitud: 0.1887\n",
      "\tNombre del archivo: dog_509.jpg, Clase: dogs, Similitud: 0.2088\n",
      "\tNombre del archivo: dog_543.jpg, Clase: dogs, Similitud: 0.2406\n",
      "\tNombre del archivo: dog_324.jpg, Clase: dogs, Similitud: 0.2505\n",
      "\tNombre del archivo: dog_128.jpg, Clase: dogs, Similitud: 0.2658\n",
      "\tNombre del archivo: dog_39.jpg, Clase: dogs, Similitud: 0.3095\n",
      "Clase: 0, Número de muestras: 348\n",
      "Clase: 1, Número de muestras: 348\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtener todos los nombres de archivo en el dataset\n",
    "filenames = [str(f) for f in dataset_dir.glob('*/*.jpg')]\n",
    "\n",
    "# Crear un mapeo de índices a nombres de archivo (solo el nombre de archivo, sin la ruta)\n",
    "filenames_dict = {i: f.name for i, f in enumerate(dataset_dir.glob('*/*.jpg'))}\n",
    "\n",
    "def show_least_similar_using_P(source_intent, target_intent, estimator, class_names, filenames_dict):\n",
    "    print(f\"{class_names[source_intent]} <> {class_names[target_intent]}\")\n",
    "    \n",
    "    # Obtener la matriz de similitud de las muestras entre las clases\n",
    "    P = estimator.P[(source_intent, target_intent)]\n",
    "    \n",
    "    # Ordenar los índices según las similitudes (de menor a mayor)\n",
    "    least_similar_indices = np.argsort(P, axis=None)\n",
    "    \n",
    "    # Conjunto para llevar un registro de los archivos ya mostrados\n",
    "    shown_files = set()\n",
    "    count = 0\n",
    "    \n",
    "    for idx in least_similar_indices:\n",
    "        if count >= 10:\n",
    "            break\n",
    "        \n",
    "        # Convertir el índice plano a índice 2D\n",
    "        idx_2d = np.unravel_index(idx, P.shape)\n",
    "        \n",
    "        # Obtener los índices de las muestras en el dataset\n",
    "        source_idx = estimator.class_indices[source_intent][idx_2d[0]]\n",
    "        target_idx = estimator.class_indices[target_intent][idx_2d[1]]\n",
    "        \n",
    "        # Verificar que los índices estén dentro de los límites del dataset\n",
    "        if source_idx < len(filenames_dict) and target_idx < len(filenames_dict):\n",
    "            source_filename = filenames_dict[int(source_idx)]\n",
    "            target_filename = filenames_dict[int(target_idx)]\n",
    "            \n",
    "            if source_filename not in shown_files and target_filename not in shown_files:\n",
    "                shown_files.add(source_filename)\n",
    "                shown_files.add(target_filename)\n",
    "                \n",
    "                value = P[idx_2d]\n",
    "                print(f\"\\tNombre del archivo: {source_filename}, Clase: {class_names[source_intent]}, Similitud: {value:.4f}\")\n",
    "                count += 1\n",
    "\n",
    "# Suponiendo que `pairs` contiene los índices de las clases en el formato [(0, 1)]\n",
    "pairs = [(0, 1)]\n",
    "\n",
    "first_pair = pairs[0]\n",
    "\n",
    "# Mostrar los menos similares usando la matriz de pares (P)\n",
    "show_least_similar_using_P(first_pair[0], first_pair[1], estimator, class_names, filenames_dict)\n",
    "show_least_similar_using_P(first_pair[1], first_pair[0], estimator, class_names, filenames_dict)\n",
    "for class_name, indices in estimator.class_indices.items():\n",
    "    print(f\"Clase: {class_name}, Número de muestras: {len(indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNombre del archivo: cat_544.jpg, Clase: cats, Similitud: 0.0508\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0508\n",
      "\tNombre del archivo: dog_403.jpg, Clase: dogs, Similitud: 0.0674\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0674\n",
      "\tNombre del archivo: dog_324.jpg, Clase: dogs, Similitud: 0.0675\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0675\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0693\n",
      "\tNombre del archivo: cat_387.jpg, Clase: cats, Similitud: 0.0693\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0693\n",
      "\tNombre del archivo: cat_446.jpg, Clase: cats, Similitud: 0.0693\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0694\n",
      "\tNombre del archivo: dog_546.jpg, Clase: dogs, Similitud: 0.0694\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0700\n",
      "\tNombre del archivo: cat_203.jpg, Clase: cats, Similitud: 0.0700\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0702\n",
      "\tNombre del archivo: cat_468.jpg, Clase: cats, Similitud: 0.0702\n",
      "\tNombre del archivo: cat_464.jpg, Clase: cats, Similitud: 0.0703\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0703\n",
      "\tNombre del archivo: cat_224.jpg, Clase: cats, Similitud: 0.0704\n",
      "\tNombre del archivo: dog_344.jpg, Clase: dogs, Similitud: 0.0704\n"
     ]
    }
   ],
   "source": [
    "# Acceder a la matriz M después de ajustar el modelo\n",
    "M = estimator.M\n",
    "\n",
    "# Ordenar los índices según las similitudes (de menor a mayor)\n",
    "least_similar_indices = np.argsort(M, axis=None)\n",
    "\n",
    "# Conjunto para llevar un registro de los archivos ya mostrados\n",
    "shown_files = set()\n",
    "count = 0\n",
    "\n",
    "# Crear un diccionario de nombres de archivo y clases\n",
    "filenames_dict = {i: f.name for i, f in enumerate(dataset_dir.glob('*/*.jpg'))}\n",
    "class_names_list = ['cats' if label == 0 else 'dogs' for label in fully_labels]\n",
    "\n",
    "# Mostrar las 10 muestras menos similares\n",
    "for idx in least_similar_indices:\n",
    "    if count >= 10:\n",
    "        break\n",
    "\n",
    "    # Convertir el índice plano a índice 2D\n",
    "    idx_2d = np.unravel_index(idx, M.shape)\n",
    "\n",
    "    # Obtener los índices de las muestras en el dataset\n",
    "    source_idx = idx_2d[0]\n",
    "    target_idx = idx_2d[1]\n",
    "\n",
    "    # Verificar que los índices estén dentro de los límites del dataset\n",
    "    if source_idx < len(filenames_dict) and target_idx < len(filenames_dict):\n",
    "        source_filename = filenames_dict[int(source_idx)]\n",
    "        target_filename = filenames_dict[int(target_idx)]\n",
    "\n",
    "        if (source_filename, target_filename) not in shown_files and (target_filename, source_filename) not in shown_files:\n",
    "            shown_files.add((source_filename, target_filename))\n",
    "            shown_files.add((target_filename, source_filename))\n",
    "\n",
    "            value = M[idx_2d]\n",
    "            print(f\"\\tNombre del archivo: {source_filename}, Clase: {class_names_list[source_idx]}, Similitud: {value:.4f}\")\n",
    "            print(f\"\\tNombre del archivo: {target_filename}, Clase: {class_names_list[target_idx]}, Similitud: {value:.4f}\")\n",
    "            count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
