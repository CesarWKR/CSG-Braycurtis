{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añadir el directorio raíz del proyecto a sys.path\n",
    "module_path = Path('/Users/Cesar/Desktop/Proyecto-CSG/').resolve()\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(str(module_path))\n",
    "\n",
    "# Añadir el directorio que contiene 'new_spectral_metric' a sys.path\n",
    "new_spectral_metric_path = module_path / '/Users/Cesar/Desktop/Proyecto-CSG/new_spectral_metric/'\n",
    "if new_spectral_metric_path not in sys.path:\n",
    "    sys.path.append(str(new_spectral_metric_path))\n",
    "\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "# from spectral_metric.lib import find_samples, compute_expectation_with_monter_carlo \n",
    "from new_spectral_metric.new_estimator import CumulativeGradientEstimator\n",
    "from new_spectral_metric.new_visualize import make_graph\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, Dense, MaxPooling2D, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET DESDE DIRECTORIO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de dataset\n",
    "directorio_dataset = ('../Datasets/CIFAR-10')\n",
    "directorio_dataset = pathlib.Path(directorio_dataset)\n",
    "\n",
    "# Lectura de la carpeta train\n",
    "directorio_train = ('../Datasets/CIFAR-10/train')\n",
    "directorio_train = pathlib.Path(directorio_train)\n",
    "\n",
    "# Lectura de la carpeta test\n",
    "directorio_test = ('../Datasets/CIFAR-10/test')\n",
    "directorio_test = pathlib.Path(directorio_test)\n",
    "\n",
    "\n",
    "total_dataset = len(list(directorio_dataset.glob('*/*/*.png')))  # Cuenta la cantidad de imagenes del dataset (Aqui busca en las subcarpetas del directorio del dataset)\n",
    "total_train = len(list(directorio_train.glob('*/*.png')))  # Cuenta la cantidad de imagenes de train\n",
    "total_test = len(list(directorio_test.glob('*/*.png')))  # Cuenta la cantidad de imagenes de test\n",
    "\n",
    "print(f\"Total imagenes dataset: {total_dataset}\")\n",
    "print(f\"Total imagenes train: {total_train}\")\n",
    "print(f\"Total imagenes test: {total_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el batchsize del dataset completo\n",
    "batch_size_total = total_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de imagen y tamaño de batch en train\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "#batch_size = 32\n",
    "batch_size_train = total_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "# Data splitting (entrenamiento y validación)\n",
    "train_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  directorio_train,\n",
    "  #validation_split=0.2,\n",
    "  color_mode='rgb',\n",
    "  label_mode='int',\n",
    "  #subset=\"training\",\n",
    "  #seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones de imagen y tamaño de batch en test\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "#batch_size = 32\n",
    "batch_size_test = total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting (entrenamiento y validación)\n",
    "test_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  directorio_test,\n",
    "  #validation_split=0.2,\n",
    "  color_mode='rgb',\n",
    "  label_mode='int',\n",
    "  #subset=\"training\",\n",
    "  #seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el total de imágenes por clase en train y test\n",
    "class_counts_total = {p.name: len(list(p.glob('*.png'))) for p in directorio_dataset.glob('*/*')}\n",
    "class_counts_train = {p.name: len(list(p.glob('*.png'))) for p in directorio_train.glob('*')}\n",
    "class_counts_test = {p.name: len(list(p.glob('*.png'))) for p in directorio_test.glob('*')}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar el total de imágenes por clase en train\n",
    "print(\"\\nTotal de imágenes por clase en train:\")\n",
    "for class_name, count in class_counts_train.items():\n",
    "    print(f\"Clase: {class_name}, Número de imágenes: {count}\")\n",
    "print(f\"Total imagenes train: {total_train}\")\n",
    "\n",
    "# Mostrar el total de imágenes por clase en test\n",
    "print(\"\\nTotal de imágenes por clase en test:\")\n",
    "for class_name, count in class_counts_test.items():\n",
    "    print(f\"Clase: {class_name}, Número de imágenes: {count}\")\n",
    "print(f\"Total imagenes test: {total_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las clases\n",
    "class_names_train = list(class_counts_train.keys())\n",
    "class_names_test = list(class_counts_test.keys())\n",
    "#class_names_total = sorted(list(set(class_names_train + class_names_test)))\n",
    "class_names_total = list(class_counts_total.keys())\n",
    "\n",
    "# Mostrar el número de clases y los nombres\n",
    "print(f\"\\nNúmero de clases en train: {len(class_names_train)}\")\n",
    "print(f\"Nombres de las clases en train: {class_names_train}\")\n",
    "\n",
    "print(f\"\\nNúmero de clases en test: {len(class_names_test)}\")\n",
    "print(f\"Nombres de las clases en test: {class_names_test}\")\n",
    "\n",
    "print(f\"\\nNúmero total de clases en el dataset: {len(class_names_total)}\")   # Este valor cambio si el nombre de las clases es diferente\n",
    "print(f\"Nombres de todas las clases en el dataset: {class_names_total}\")     # Este valor tambien cambia si el nombre de las clases es diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels0 in train_images.take(1):  # only take first element of dataset\n",
    "    numpy_all_images = images.numpy()  # convertir el tensor de imágenes en un arreglo de numpy y ahora contiene las imágenes del conjunto de datos en formato de numpy.\n",
    "    numpy_all_labels = labels0.numpy()  # convierte el tensor de etiquetas en un arreglo de numpy y ahora contiene las etiquetas del conjunto de datos en formato de numpy\n",
    "\n",
    "numpy_all_images /= 255.0  # Scale the features to the [0, 1] range\n",
    "print(numpy_all_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset complexity using CSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 Two classes\n",
    "fully_dataset = numpy_all_images.reshape((numpy_all_images.shape[0], numpy_all_images.shape[1]*numpy_all_images.shape[2]*numpy_all_images.shape[3])) # es un arreglo bidimensional donde cada fila representa una imagen y cada columna representa un píxel de la imagen\n",
    "fully_labels = numpy_all_labels.reshape(numpy_all_labels.shape[0],)\n",
    "\n",
    "estimator = CumulativeGradientEstimator(M_sample=1000, k_nearest=10)\n",
    "estimator.fit(data=fully_dataset, target=fully_labels)\n",
    "csg = estimator.csg  # The actual complexity values.\n",
    "estimator.evals, estimator.evecs  # The eigenvalues and vectors.\n",
    "\n",
    "make_graph(estimator.difference, title=\"Comparative between two clases, CSG: \"+str(csg), classes=class_names_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "\n",
    "# Calcular la entropía por clase  \n",
    "entropy_per_class = entropy(estimator.W / estimator.W.sum(-1)[:, None], axis=-1)  \n",
    "\n",
    "# Encontrar la clase menos confusa (menor entropía)  \n",
    "least_confused_class_index = np.argmin(entropy_per_class)  \n",
    "least_confused_class_name = class_names_train[least_confused_class_index]  \n",
    "\n",
    "print(\"Class that is the least confused (lowest entropy):\", least_confused_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Obtener los índices de los pares menos similares  \n",
    "pairs = list(zip(*np.unravel_index(np.argsort(estimator.W, axis=None), estimator.W.shape)))  \n",
    "\n",
    "# Filtrar pares donde i != j para evitar pares de la misma clase  \n",
    "pairs = [(i, j) for i, j in pairs if i != j]  \n",
    "\n",
    "print(\"Least similar pairs\")  \n",
    "lst = []  \n",
    "seen_pairs = set()  \n",
    "\n",
    "# Iterar sobre los primeros 10 pares menos similares  \n",
    "for i, j in pairs:  \n",
    "    # Verificar si el par o su inverso ya ha sido visto  \n",
    "    if (i, j) not in seen_pairs and (j, i) not in seen_pairs:  \n",
    "        lst.append({\"Intent pair\": f\"{class_names_train[i]} <> {class_names_train[j]}\", \"Similarity\": estimator.W[i, j]})  \n",
    "        seen_pairs.add((i, j))  \n",
    "        seen_pairs.add((j, i))  \n",
    "    \n",
    "    # Detenerse después de encontrar 10 pares únicos  \n",
    "    if len(lst) == 10:  \n",
    "        break  \n",
    "\n",
    "# Mostrar los resultados en un DataFrame  \n",
    "print(pd.DataFrame(lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerias de pytorch para la comparativa entre muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "import torchvision.transforms as transforms  \n",
    "from torchvision.datasets import ImageFolder  \n",
    "from PIL import Image  \n",
    "import pathlib  \n",
    "import cupy as cp \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets\n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar la disponibilidad de la GPU  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "print(\"Nombre de la GPU:\", torch.cuda.get_device_name() if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para preprocesamiento de datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),  # Ajustar tamaño a 32x32\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = pathlib.Path(directory)\n",
    "        self.transform = transform\n",
    "        self.images = list(self.directory.glob('*.png'))\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.images)  \n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        img_path = self.images[idx]  \n",
    "        image = Image.open(img_path).convert('RGB')  \n",
    "        if self.transform:  \n",
    "            image = self.transform(image)  \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets personalizados\n",
    "dataset_completo = datasets.ImageFolder(root=str(directorio_dataset), transform=transform)\n",
    "dataset_train = datasets.ImageFolder(root=str(directorio_train), transform=transform)\n",
    "dataset_test = datasets.ImageFolder(root=str(directorio_test), transform=transform)\n",
    "\n",
    "# Crear el DataLoader para iterar sobre los datos en lotes\n",
    "dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size_total, shuffle=False, num_workers=0)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size_train, shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener los nombres de las imagenes en train o test (dependiendo de lo que se quiera probar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los nombres de archivo en en train\n",
    "filenames = [str(f) for f in directorio_train.glob('*/*.png')]\n",
    "\n",
    "# Crear un mapeo de índices a rutas completas de archivo en train  \n",
    "filenames_dict = {i: str(f) for i, f in enumerate(directorio_train.glob('*/*.png'))} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
