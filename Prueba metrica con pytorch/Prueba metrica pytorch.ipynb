{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import scipy.spatial\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np  \n",
    "import torch  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "import torchvision.transforms as transforms  \n",
    "from torchvision.datasets import ImageFolder  \n",
    "from PIL import Image  \n",
    "import pathlib  \n",
    "import cupy as cp \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añadir el directorio raíz del proyecto a sys.path\n",
    "module_path = Path('/Users/Cesar/Desktop/Proyecto-CSG/').resolve()\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(str(module_path))\n",
    "\n",
    "# Añadir el directorio que contiene 'new_spectral_metric' a sys.path\n",
    "new_spectral_metric_path = module_path / '/Users/Cesar/Desktop/Proyecto-CSG/pytorch_spectral_metric'\n",
    "if new_spectral_metric_path not in sys.path:\n",
    "    sys.path.append(str(new_spectral_metric_path))\n",
    "\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from pytorch_spectral_metric.estimator_pytorch import CumulativeGradientEstimator\n",
    "from pytorch_spectral_metric.visualize_pytorch import make_graph\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, Dense, MaxPooling2D, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# Verificar la disponibilidad de la GPU  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "print(\"Nombre de la GPU:\", torch.cuda.get_device_name() if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes dataset: 10000\n",
      "Total imágenes originales: 5000\n",
      "Total imágenes corruptas: 5000\n"
     ]
    }
   ],
   "source": [
    "# Definir directorios\n",
    "directorio_dataset = '../Datasets/CIFAR-10 dos clases'\n",
    "imagenes_originales = '../Datasets/CIFAR-10 dos clases/cat'\n",
    "imagenes_corruptas = '../Datasets/CIFAR-10 dos clases/cat_c_defocus_blur'\n",
    "\n",
    "directorio_dataset = pathlib.Path(directorio_dataset)\n",
    "imagenes_originales = pathlib.Path(imagenes_originales)\n",
    "imagenes_corruptas = pathlib.Path(imagenes_corruptas)\n",
    "\n",
    "\n",
    "\n",
    "# Dimensiones de imagen y tamaño de batch\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "#batch_size = len(list(data_dir.glob('*/*.png'))) # leer todas las imágenes al tiempo\n",
    "\n",
    "\n",
    "# Transformaciones para preprocesamiento de datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),  # Ajustar tamaño a 32x32\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = pathlib.Path(directory)\n",
    "        self.transform = transform\n",
    "        self.images = list(self.directory.glob('*.png'))\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.images)  \n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        img_path = self.images[idx]  \n",
    "        image = Image.open(img_path).convert('RGB')  \n",
    "        if self.transform:  \n",
    "            image = self.transform(image)  \n",
    "        return image\n",
    "\n",
    "\n",
    "# Crear datasets personalizados\n",
    "dataset_completo = datasets.ImageFolder(root=directorio_dataset, transform=transform)\n",
    "dataset_originales = CustomImageDataset(imagenes_originales, transform=transform)\n",
    "dataset_corruptas = CustomImageDataset(imagenes_corruptas, transform=transform)\n",
    "\n",
    "# Calcular totales\n",
    "total_dataset = len(dataset_originales) + len(dataset_corruptas)\n",
    "total_originales = len(dataset_originales)\n",
    "total_corruptas = len(dataset_corruptas)\n",
    "\n",
    "batch_size = total_dataset\n",
    "\n",
    "\n",
    "\n",
    "# Crear el DataLoader para iterar sobre los datos en lotes\n",
    "# DataLoader para cargar los datasets\n",
    "dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "dataloader_originales = DataLoader(dataset_originales, batch_size=batch_size, shuffle=False)\n",
    "dataloader_corruptas = DataLoader(dataset_corruptas, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # DataLoader para cargar los datasets  \n",
    "# dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size, shuffle=False, num_workers=0)  \n",
    "\n",
    "print(f\"Total imágenes dataset: {total_dataset}\")  \n",
    "print(f\"Total imágenes originales: {total_originales}\")  \n",
    "print(f\"Total imágenes corruptas: {total_corruptas}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases: 2\n",
      "Los nombres de las clases son: ['cat', 'cat_c_defocus_blur']\n"
     ]
    }
   ],
   "source": [
    "# Acceder a las clases\n",
    "\n",
    "class_names = dataset_completo.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Número de clases: {num_classes}\")\n",
    "print(f\"Los nombres de las clases son: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre los datos para obtener el primer lote  \n",
    "for images, labels in dataloader_completo:  \n",
    "    # Mover datos a la GPU si es posible  \n",
    "    images, labels = images.to(device), labels.to(device)  \n",
    "    \n",
    "    # Si deseas mantener las imágenes en su forma original (no aplanadas), simplemente omite la aplanación  \n",
    "    if device.type == 'cuda':  \n",
    "        numpy_all_images = cp.array(images.cpu().numpy())  # Mantiene la forma original  \n",
    "        numpy_all_labels = cp.array(labels.cpu().numpy())  \n",
    "    else:  \n",
    "        numpy_all_images = cp.array(images.numpy())  # Mantiene la forma original  \n",
    "        numpy_all_labels = cp.array(labels.numpy())  \n",
    "    \n",
    "    print(numpy_all_images.shape)  # Esto debería imprimir (10000, 3, 32, 32)  \n",
    "    break  # Solo tomamos el primer lote para imprimir las dimensiones  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m target_np \u001b[38;5;241m=\u001b[39m numpy_all_labels\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(numpy_all_labels, cp\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m numpy_all_labels  \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Ajustar el modelo con los datos y etiquetas convertidos  \u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_np\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     10\u001b[0m csg \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mcsg  \u001b[38;5;66;03m# The actual complexity values.  \u001b[39;00m\n\u001b[0;32m     11\u001b[0m estimator\u001b[38;5;241m.\u001b[39mevals, estimator\u001b[38;5;241m.\u001b[39mevecs  \u001b[38;5;66;03m# The eigenvalues and vectors.  \u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\pytorch_spectral_metric\\estimator_pytorch.py:27\u001b[0m, in \u001b[0;36mCumulativeGradientEstimator.fit\u001b[1;34m(self, data, target)\u001b[0m\n\u001b[0;32m     24\u001b[0m data_x \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39marray(data)  \u001b[38;5;66;03m# Convertir a CuPy para procesamiento en GPU  \u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mmax(target) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m0\u001b[39m, cp\u001b[38;5;241m.\u001b[39mmin(target)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \n\u001b[1;32m---> 27\u001b[0m class_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_indices \u001b[38;5;241m=\u001b[39m \u001b[43mfind_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mM_sample\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute(data_x, cp\u001b[38;5;241m.\u001b[39marray(target), class_samples)  \n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\pytorch_spectral_metric\\lib_pytorch.py:86\u001b[0m, in \u001b[0;36mfind_samples\u001b[1;34m(data, target, n_class, M, seed)\u001b[0m\n\u001b[0;32m     84\u001b[0m     indices_in_cls \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mpermutation(cp\u001b[38;5;241m.\u001b[39masnumpy(indices[target \u001b[38;5;241m==\u001b[39m k]))  \n\u001b[0;32m     85\u001b[0m     to_take \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(M \u001b[38;5;28;01mif\u001b[39;00m M \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mint\u001b[39m(M \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(indices_in_cls)), \u001b[38;5;28mlen\u001b[39m(indices_in_cls))  \n\u001b[1;32m---> 86\u001b[0m     \u001b[43mclass_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m data[indices_in_cls[:to_take]]  \n\u001b[0;32m     87\u001b[0m     class_indices[k] \u001b[38;5;241m=\u001b[39m indices_in_cls[:to_take]  \n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m class_samples, class_indices\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'ndarray'"
     ]
    }
   ],
   "source": [
    "# Inicializar el estimador  \n",
    "estimator = CumulativeGradientEstimator(M_sample=348, k_nearest=10)  \n",
    "\n",
    "# Convertir a un ndarray de NumPy si numpy_all_images o numpy_all_labels son de tipo cp.ndarray  \n",
    "data_np = numpy_all_images.get() if isinstance(numpy_all_images, cp.ndarray) else numpy_all_images  \n",
    "target_np = numpy_all_labels.get() if isinstance(numpy_all_labels, cp.ndarray) else numpy_all_labels  \n",
    "\n",
    "# Ajustar el modelo con los datos y etiquetas convertidos  \n",
    "estimator.fit(data=data_np, target=target_np)  \n",
    "csg = estimator.csg  # The actual complexity values.  \n",
    "estimator.evals, estimator.evecs  # The eigenvalues and vectors.  \n",
    "\n",
    "# Asegúrate de que tienes un entorno gráfico activo al usar esta función  \n",
    "make_graph(estimator.difference, title=f\"Comparative between two classes, CSG: {csg}\", classes=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
