{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import scipy.spatial\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np  \n",
    "import torch  \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "import torchvision.transforms as transforms  \n",
    "from torchvision.datasets import ImageFolder  \n",
    "from PIL import Image  \n",
    "import pathlib  \n",
    "import cupy as cp \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Añadir el directorio raíz del proyecto a sys.path\n",
    "module_path = Path('/Users/Cesar/Desktop/Proyecto-CSG/').resolve()\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(str(module_path))\n",
    "\n",
    "# Añadir el directorio que contiene 'new_spectral_metric' a sys.path\n",
    "new_spectral_metric_path = module_path / '/Users/Cesar/Desktop/Proyecto-CSG/pytorch_spectral_metric'\n",
    "if new_spectral_metric_path not in sys.path:\n",
    "    sys.path.append(str(new_spectral_metric_path))\n",
    "\n",
    "from numpy.linalg import LinAlgError\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from pytorch_spectral_metric.estimator_pytorch import CumulativeGradientEstimator\n",
    "from pytorch_spectral_metric.visualize_pytorch import make_graph\n",
    "from pathlib import Path\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: True\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "# Verificar la disponibilidad de la GPU  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "print(\"Nombre de la GPU:\", torch.cuda.get_device_name() if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imágenes dataset: 10000\n",
      "Total imágenes originales: 5000\n",
      "Total imágenes corruptas: 5000\n"
     ]
    }
   ],
   "source": [
    "# Definir directorios\n",
    "directorio_dataset = '../Datasets/CIFAR-10 dos clases'\n",
    "imagenes_originales = '../Datasets/CIFAR-10 dos clases/cat'\n",
    "imagenes_corruptas = '../Datasets/CIFAR-10 dos clases/cat_c_defocus_blur'\n",
    "\n",
    "directorio_dataset = pathlib.Path(directorio_dataset)\n",
    "imagenes_originales = pathlib.Path(imagenes_originales)\n",
    "imagenes_corruptas = pathlib.Path(imagenes_corruptas)\n",
    "\n",
    "\n",
    "\n",
    "# Dimensiones de imagen y tamaño de batch\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "#batch_size = len(list(data_dir.glob('*/*.png'))) # leer todas las imágenes al tiempo\n",
    "\n",
    "\n",
    "# Transformaciones para preprocesamiento de datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),  # Ajustar tamaño a 32x32\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = pathlib.Path(directory)\n",
    "        self.transform = transform\n",
    "        self.images = list(self.directory.glob('*.png'))\n",
    "\n",
    "    def __len__(self):  \n",
    "        return len(self.images)  \n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        img_path = self.images[idx]  \n",
    "        image = Image.open(img_path).convert('RGB')  \n",
    "        if self.transform:  \n",
    "            image = self.transform(image)  \n",
    "        return image\n",
    "\n",
    "\n",
    "# Crear datasets personalizados\n",
    "dataset_completo = datasets.ImageFolder(root=directorio_dataset, transform=transform)\n",
    "dataset_originales = CustomImageDataset(imagenes_originales, transform=transform)\n",
    "dataset_corruptas = CustomImageDataset(imagenes_corruptas, transform=transform)\n",
    "\n",
    "# Calcular totales\n",
    "total_dataset = len(dataset_originales) + len(dataset_corruptas)\n",
    "total_originales = len(dataset_originales)\n",
    "total_corruptas = len(dataset_corruptas)\n",
    "\n",
    "batch_size = total_dataset\n",
    "\n",
    "\n",
    "\n",
    "# Crear el DataLoader para iterar sobre los datos en lotes\n",
    "# DataLoader para cargar los datasets\n",
    "dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "dataloader_originales = DataLoader(dataset_originales, batch_size=batch_size, shuffle=False)\n",
    "dataloader_corruptas = DataLoader(dataset_corruptas, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # DataLoader para cargar los datasets  \n",
    "# dataloader_completo = DataLoader(dataset_completo, batch_size=batch_size, shuffle=False, num_workers=0)  \n",
    "\n",
    "print(f\"Total imágenes dataset: {total_dataset}\")  \n",
    "print(f\"Total imágenes originales: {total_originales}\")  \n",
    "print(f\"Total imágenes corruptas: {total_corruptas}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases: 2\n",
      "Los nombres de las clases son: ['cat', 'cat_c_defocus_blur']\n"
     ]
    }
   ],
   "source": [
    "# Acceder a las clases\n",
    "\n",
    "class_names = dataset_completo.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Número de clases: {num_classes}\")\n",
    "print(f\"Los nombres de las clases son: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Iterar sobre los datos para obtener el primer lote  \n",
    "for images, labels in dataloader_completo:  \n",
    "    # Mover datos a la GPU si es posible  \n",
    "    images, labels = images.to(device), labels.to(device)  \n",
    "    \n",
    "    # Si deseas mantener las imágenes en su forma original (no aplanadas), simplemente omite la aplanación  \n",
    "    if device.type == 'cuda':  \n",
    "        numpy_all_images = cp.array(images.cpu().numpy())  # Mantiene la forma original  \n",
    "        numpy_all_labels = cp.array(labels.cpu().numpy())  \n",
    "    else:  \n",
    "        numpy_all_images = cp.array(images.numpy())  # Mantiene la forma original  \n",
    "        numpy_all_labels = cp.array(labels.numpy())  \n",
    "    \n",
    "    print(numpy_all_images.shape)  # Esto debería imprimir (10000, 3, 32, 32)  \n",
    "    break  # Solo tomamos el primer lote para imprimir las dimensiones  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of k: <class 'cupy.ndarray'>, Value of k: 0\n",
      "Type of k: <class 'cupy.ndarray'>, Value of k: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. check_pairwise_arrays expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m target_np \u001b[38;5;241m=\u001b[39m numpy_all_labels\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(numpy_all_labels, cp\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m numpy_all_labels  \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Ajustar el modelo con los datos y etiquetas convertidos  \u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_np\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     10\u001b[0m csg \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mcsg  \u001b[38;5;66;03m# The actual complexity values.  \u001b[39;00m\n\u001b[0;32m     11\u001b[0m estimator\u001b[38;5;241m.\u001b[39mevals, estimator\u001b[38;5;241m.\u001b[39mevecs  \u001b[38;5;66;03m# The eigenvalues and vectors.  \u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\pytorch_spectral_metric\\estimator_pytorch.py:31\u001b[0m, in \u001b[0;36mCumulativeGradientEstimator.fit\u001b[1;34m(self, data, target)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mmax(target) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m0\u001b[39m, cp\u001b[38;5;241m.\u001b[39mmin(target)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \n\u001b[0;32m     27\u001b[0m class_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_indices \u001b[38;5;241m=\u001b[39m find_samples(  \n\u001b[0;32m     28\u001b[0m     data_x, cp\u001b[38;5;241m.\u001b[39marray(target), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class, M\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM_sample  \n\u001b[0;32m     29\u001b[0m )  \n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_samples\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\pytorch_spectral_metric\\estimator_pytorch.py:35\u001b[0m, in \u001b[0;36mCumulativeGradientEstimator.compute\u001b[1;34m(self, data, target, class_samples)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, target, class_samples):  \n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_arrays \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_expectation_with_monte_carlo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk_nearest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_nearest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class)  \n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m product(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class), \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_class)):  \n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\pytorch_spectral_metric\\lib_pytorch.py:38\u001b[0m, in \u001b[0;36mcompute_expectation_with_monte_carlo\u001b[1;34m(data, target, class_samples, class_indices, n_class, k_nearest, distance)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cp\u001b[38;5;241m.\u001b[39marray(pairwise_distances(cp\u001b[38;5;241m.\u001b[39masnumpy(class_samples[k]), cp\u001b[38;5;241m.\u001b[39masnumpy(data), metric\u001b[38;5;241m=\u001b[39mdistance))  \n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_ix \u001b[38;5;129;01min\u001b[39;00m class_samples:  \n\u001b[1;32m---> 38\u001b[0m     all_similarities \u001b[38;5;241m=\u001b[39m \u001b[43msimilarities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_ix\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     39\u001b[0m     all_indices \u001b[38;5;241m=\u001b[39m class_indices[class_ix]  \n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m, sample_ix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_indices):  \n",
      "File \u001b[1;32m~\\Desktop\\Proyecto-CSG\\pytorch_spectral_metric\\lib_pytorch.py:35\u001b[0m, in \u001b[0;36mcompute_expectation_with_monte_carlo.<locals>.similarities\u001b[1;34m(k)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarities\u001b[39m(k):  \n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cp\u001b[38;5;241m.\u001b[39marray(\u001b[43mpairwise_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Cesar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Cesar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2331\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2328\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2329\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parallel_pairwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Cesar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1871\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1868\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1874\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32mc:\\Users\\Cesar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Cesar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:319\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    234\u001b[0m     {\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m     X, Y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, Y_norm_squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, X_norm_squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m ):\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    Compute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m           [1.41421356]])\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X_norm_squared \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m         X_norm_squared \u001b[38;5;241m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Cesar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:164\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    155\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    156\u001b[0m         X,\n\u001b[0;32m    157\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    173\u001b[0m         Y,\n\u001b[0;32m    174\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32mc:\\Users\\Cesar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1043\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1041\u001b[0m     )\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m   1049\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1050\u001b[0m         array,\n\u001b[0;32m   1051\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1052\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1053\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1054\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 4. check_pairwise_arrays expected <= 2."
     ]
    }
   ],
   "source": [
    "# Inicializar el estimador  \n",
    "estimator = CumulativeGradientEstimator(M_sample=348, k_nearest=10)  \n",
    "\n",
    "# Convertir a un ndarray de NumPy si numpy_all_images o numpy_all_labels son de tipo cp.ndarray  \n",
    "data_np = numpy_all_images.get() if isinstance(numpy_all_images, cp.ndarray) else numpy_all_images  \n",
    "target_np = numpy_all_labels.get() if isinstance(numpy_all_labels, cp.ndarray) else numpy_all_labels  \n",
    "\n",
    "# Ajustar el modelo con los datos y etiquetas convertidos  \n",
    "estimator.fit(data=data_np, target=target_np)  \n",
    "csg = estimator.csg  # The actual complexity values.  \n",
    "estimator.evals, estimator.evecs  # The eigenvalues and vectors.  \n",
    "\n",
    "# Asegúrate de que tienes un entorno gráfico activo al usar esta función  \n",
    "make_graph(estimator.difference, title=f\"Comparative between two classes, CSG: {csg}\", classes=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
